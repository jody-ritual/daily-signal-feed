<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Signal Feed ‚Äî AI, Web3 & Emerging Trends</title>
    <link rel="stylesheet" href="/daily-signal-feed/css/style.css">
    <meta name="description" content="AI, Web3, and emerging tech news aggregated from 50+ sources with trend detection.">
</head>
<body>
    <header class="site-header">
        <div class="container header-inner">
            <a href="/daily-signal-feed/" class="site-logo">
                <h1>Daily Signal Feed</h1>
                <span class="tagline">AI &bull; Web3 &bull; Emerging Trends</span>
            </a>
            <nav class="main-nav">
                <a href="/daily-signal-feed/" class="active">Home</a>
                
                <a href="/daily-signal-feed/category/ai-llms.html"
                   class="">
                    AI &amp; LLMs (407)
                </a>
                
                <a href="/daily-signal-feed/category/web3-defi.html"
                   class="">
                    Web3 &amp; DeFi (14)
                </a>
                
                <a href="/daily-signal-feed/category/deals.html"
                   class="">
                    Deals &amp; Acquisitions (2)
                </a>
                
                <a href="/daily-signal-feed/category/new-tools.html"
                   class="">
                    New Tools &amp; Apps (5)
                </a>
                
                <a href="/daily-signal-feed/category/regulation.html"
                   class="">
                    Regulation &amp; Policy
                </a>
                
                <a href="/daily-signal-feed/category/social-buzz.html"
                   class="">
                    Social Buzz (65)
                </a>
                
                <a href="/daily-signal-feed/category/emerging-trends.html"
                   class="">
                    Emerging Trends
                </a>
                
                <a href="/daily-signal-feed/archive.html" class="">Archive</a>
            </nav>
        </div>
    </header>

    <main class="container">
        
<!-- Executive Summary -->
<section class="exec-summary">
    <h2>Signal Summary</h2>

    <div class="summary-grid">
        <!-- Trending Topics -->
        <div class="summary-card">
            <h3>Trending Now</h3>
            <ul class="trend-list">
                
                <li class="trend-item">
                    <span class="trend-term">MLLMs</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">11 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">MRI</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">9 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Thought</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">6 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Benchmark</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">An</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Traditional</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">7 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Generative</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">4 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
            </ul>
        </div>

        <!-- Category Activity -->
        <div class="summary-card">
            <h3>Category Activity</h3>
            <div class="cat-bars">
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">AI &amp; LLMs</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 100%; background: #4F46E5;"></div>
                    </div>
                    <span class="cat-bar-count">407</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Social Buzz</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 16%; background: #06B6D4;"></div>
                    </div>
                    <span class="cat-bar-count">65</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Web3 &amp; DeFi</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 3%; background: #8B5CF6;"></div>
                    </div>
                    <span class="cat-bar-count">14</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">New Tools &amp; Apps</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 1%; background: #F59E0B;"></div>
                    </div>
                    <span class="cat-bar-count">5</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Deals &amp; Acquisitions</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 0%; background: #EC4899;"></div>
                    </div>
                    <span class="cat-bar-count">2</span>
                </div>
                
                
                
                
                
                
            </div>
        </div>

        <!-- Stats -->
        <div class="summary-card">
            <h3>Today's Signal</h3>
            <div class="stat-grid">
                <div class="stat-item">
                    <div class="stat-value">493</div>
                    <div class="stat-label">Articles</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">19</div>
                    <div class="stat-label">Sources</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">34</div>
                    <div class="stat-label">Trending</div>
                </div>
                <div class="stat-item">
                    <span class="momentum-badge momentum-accelerating">
                        accelerating
                    </span>
                    <div class="stat-label">Momentum</div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Search -->
<input type="text" class="search-bar" placeholder="Search articles by title, source, or keyword..." aria-label="Search articles">

<!-- Trending Articles -->

<section>
    <div class="section-header">
        <h2>Trending Now</h2>
    </div>
    <div class="article-grid">
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">16m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/animoca-brands-dubai-vara-vasp-license-middle-east?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Animoca Brands wins Dubai crypto license to expand services in Middle East</a>
    </h3>

    
    <p class="card-summary">Dubai‚Äôs regulator approved the license on Feb. 5, allowing Animoca Brands to target institutional and qualified investors under the oversight of Dubai‚Äôs VARA.</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r61ir4/agent_vs_humans_hackathon/" target="_blank" rel="noopener">Agent vs Humans Hackathon</a>
    </h3>

    
    <p class="card-summary">Hi everyone, I‚Äôm putting together a new kind of hackathon: the Agent vs Humans Hackathon (Feb 21 - Mar 1). Core goal is to test out how agents can work autonomously at one shot. From Agent&#39;s side - the dev should just single shot the full prompt and the agent runs the entire stuff autonomously. No additional feedback or prompting back. Currently, it is From humans side - Humans is technically...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r60qu9/ama_announcement_stepfun_ai_the_opensource_lab/" target="_blank" rel="noopener">AMA Announcement: StepFun AI, The Opensource Lab Behind Step-3.5-Flash Model (Thursday, 8AM-11AM PST)</a>
    </h3>

    
    <p class="card-summary">Hi r/LocalLLaMA üëã We&#39;re excited for Thursday&#39;s guests: The StepFun Team! Kicking things off Thursday, Feb. 19th, 8 AM‚Äì11 AM PST ‚ö†Ô∏è Note: The AMA itself will be hosted in a separate thread, please don‚Äôt post questions here. &amp;#32; submitted by &amp;#32; /u/XMasterrrr [link] &amp;#32; [comments]</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">8m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r6397b/is_ai_any_good_at_unblurring_gaussian_blur/" target="_blank" rel="noopener">Is AI any good at unblurring gaussian blur?</a>
    </h3>

    
    <p class="card-summary">I recently watched this YouTube video of someone who used an AI model to &amp;quot;de-censor&amp;quot; or de-piexlate an image of their desktop, and I was intrigued that it was possible (Images 1&amp;amp;2): Source: https://www.youtube.com/watch?v=acKYYwcxpGk However, I was wondering if anything out there could do the same or something similar to this by recovering faces through gaussian blur. And no I don&#39;t...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/startups</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/startups/comments/1r60jlm/hiringseekingoffering_jobs_cofounders_weekly/" target="_blank" rel="noopener">[Hiring/Seeking/Offering] Jobs / Co-Founders Weekly Thread</a>
    </h3>

    
    <p class="card-summary">[Hiring/Seeking/Offering] Jobs / Co-Founders Weekly Thread This is an experiment. We see there is a demand from the community to: Find Co-Founders Hiring / Seeking Jobs Offering Your Skillset / Looking for Talent Please use the following template: **[SEEKING / HIRING / OFFERING]** (Choose one) **[COFOUNDER / JOB / OFFER]** (Choose one) Company Name: (Optional) Pitch: Preferred Contact Method(s)...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12287" target="_blank" rel="noopener">Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12287v1 Announce Type: new Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large...</p>
    

    
</article>
        
    </div>
</section>


<!-- Latest by Date -->

<h3 class="date-label">February 16, 2026</h3>
<div class="article-grid">
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">8m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r6397b/is_ai_any_good_at_unblurring_gaussian_blur/" target="_blank" rel="noopener">Is AI any good at unblurring gaussian blur?</a>
    </h3>

    
    <p class="card-summary">I recently watched this YouTube video of someone who used an AI model to &amp;quot;de-censor&amp;quot; or de-piexlate an image of their desktop, and I was intrigued that it was possible (Images 1&amp;amp;2): Source: https://www.youtube.com/watch?v=acKYYwcxpGk However, I was wondering if anything out there could do the same or something similar to this by recovering faces through gaussian blur. And no I don&#39;t...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/SideProject</span>
        <span class="card-category" style="background: #F59E0B;">
            New Tools &amp; Apps
        </span>
        <span class="card-time">8m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/SideProject/comments/1r6396r/tool_to_fight_urges/" target="_blank" rel="noopener">Tool to fight urges</a>
    </h3>

    
    <p class="card-summary">Hey r/SideProject, I‚Äôve been working on a web app called urges.app. I built it because most habit trackers feel like games. They give you little digital badges and confetti when you hit a milestone, but if you‚Äôre actually struggling with an addiction or an urge, a cartoon trophy doesn&#39;t help. My philosophy The goal isn&#39;t to make you feel good; it‚Äôs to provide a discipline layer. No ads, no...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">13m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r635nu/is_there_a_way_to_stop_sora_2_from_changing/" target="_blank" rel="noopener">Is there a way to stop Sora 2 from changing styles for animated remixes?</a>
    </h3>

    
    <p class="card-summary">Lately when I try to remix one of my animated videos, it completely changes the style of animation. The first image is the original video, the second is what it keeps remixing to. I want it to keep the original style. I&#39;ve tried things like, &amp;quot;Keep the original style.&amp;quot; and even &amp;quot;Keep the flat vector illustration style from the Original video&amp;quot; and things like that. Or even...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">16m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/animoca-brands-dubai-vara-vasp-license-middle-east?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Animoca Brands wins Dubai crypto license to expand services in Middle East</a>
    </h3>

    
    <p class="card-summary">Dubai‚Äôs regulator approved the license on Feb. 5, allowing Animoca Brands to target institutional and qualified investors under the oversight of Dubai‚Äôs VARA.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/defi</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">22m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/defi/comments/1r630lj/are_algorithmic_stablecoins_fundamentally_fragile/" target="_blank" rel="noopener">Are algorithmic stablecoins fundamentally fragile, or just early?</a>
    </h3>

    
    <p class="card-summary">I‚Äôve been learning about stablecoins and came across algorithmic stablecoins, the type that uses algorithms and smart contracts to control supply and keep the price stable. The idea feels very elegant to me. Instead of backing the stablecoin with actual dollars or crypto collateral, the system just adjusts supply automatically based on demand. In theory, it‚Äôs like a self-balancing economy. But...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">26m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r62yba/openai_grabs_openclaw_creator_peter_steinberger/" target="_blank" rel="noopener">OpenAI grabs OpenClaw creator Peter Steinberger to build personal agents</a>
    </h3>

    
    <p class="card-summary">Sam Altman just announced the hiring of Peter Steinberger, creator of the viral open-source AI agent OpenClaw (formerly Clawdbot). Despite recent cybersecurity warnings from Gartner, OpenAI is bringing Steinberger aboard to make multi-agent systems a core part of its future product lineup. &amp;#32; submitted by &amp;#32; /u/EchoOfOppenheimer [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">27m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r62xca/help_on_making_lora/" target="_blank" rel="noopener">Help on making Lora</a>
    </h3>

    
    <p class="card-summary">So I want to try making my own Lora and I ran into my first roadblock. I wanted to make it for Itori from tokyo ghoul but there are only like 10 pictures of her and most of them kinda look the same except for a slight angling of her head. I wanted to ask someone to make it for me but Im kinda broke as of now, so I have to rely on my own. I&#39;ve seen on civit that there are Lora&#39;s for the most niche...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">33m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r62tlh/bb25_bayesian_bm25_v020_is_out/" target="_blank" rel="noopener">bb25 (Bayesian BM25) v0.2.0 is out!</a>
    </h3>

    
    <p class="card-summary">bb25 v0.2.0 is out ‚Äî a Python + Rust implementation of Bayesian BM25 that turns search scores into calibrated probabilities. https://github.com/instructkr/bb25 A week ago, I built bb25 that turns BM25 into a probability engine! In addition to the Rust-based implementation, the paper&#39;s author shipped his own implementation. Comparing the two taught me more than the paper itself. The Bayesian BM25...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">50m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/16/crypto-market-drowns-in-red-as-bitcoin-falls-to-usd68-000" target="_blank" rel="noopener">Crypto market drowns in red as bitcoin falls to $68,000</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">52m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r62hju/if_you_are_traveling_for_this_do_connect/" target="_blank" rel="noopener">If you are traveling for this , do connect ü•∞</a>
    </h3>

    
    <p class="card-summary">I‚Äôve been building Satya with OpenAI and would be interested to discuss some unique points . &amp;#32; submitted by &amp;#32; /u/Astrokanu [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r62bf7/what_is_adapters/" target="_blank" rel="noopener">What is Adapters ?</a>
    </h3>

    
    <p class="card-summary">Hello there, I‚Äôm noob here, what is Adapters actually do ? &amp;#32; submitted by &amp;#32; /u/PhilosopherSweaty826 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r6240y/chat_gpt_is_worse_now_than_ive_ever_seen_it/" target="_blank" rel="noopener">Chat GPT is worse now than I&#39;ve ever seen it</a>
    </h3>

    
    <p class="card-summary">I ask it the most basic questions and ask it to provide links and information but it is wrong about things about 80% of the time because I will have to go and do my own research come back tell it to the AI and then it says oh my bad I was wrong after I repeatedly told it to research again it&#39;s never been this bad it used to be much better but I&#39;ve deleted the app earlier today because of how bad...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/cryptocurrency</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/CryptoCurrency/comments/1r61zxh/ray_dalio_says_the_world_order_has_broken_down/" target="_blank" rel="noopener">Ray Dalio Says the World Order Has Broken Down: What Does It Mean for Crypto?</a>
    </h3>

    
    <p class="card-summary">&amp;#32; submitted by &amp;#32; /u/DirectionMundane5468 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/bitcoin-track-for-worst-q1-since-2018-first-ever-red-jan-and-feb?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Bitcoin down 22%, could it be the worst Q1 since 2018?</a>
    </h3>

    
    <p class="card-summary">If Bitcoin posts a loss at the end of this month, it will also mark Bitcoin‚Äôs first time ending both January and February in the red.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/russian-finance-ministry-reveals-648m-daily-crypto-volume-amid-regulatory-push?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Russians move $129B in crypto yearly ‚Äòoutside our attention‚Äô: Official</a>
    </h3>

    
    <p class="card-summary">Russia‚Äôs deputy finance minister says around 50 billion rubles worth of crypto changes hands daily, calling for crypto market regulation.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/MachineLearning</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/MachineLearning/comments/1r61vx9/d_i_was_told_there_would_be_no_math_why_many_ml/" target="_blank" rel="noopener">[D] ‚ÄúI Was Told There Would Be No Math‚Äù Why many ML projects fail before the model</a>
    </h3>

    
    <p class="card-summary">I have been doing machine learning for less than a year. My background is 25 years as a technical architect across financial services, healthcare, and education. I have worked on fixed income risk analytics, mortgage modeling using Monte Carlo simulation, Medicaid and Medicare law aggregation with legal review, and subsidy management systems for the State of Massachusetts. My career has mostly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r61upn/anyone_shipping_production_apps_or_prototypes/" target="_blank" rel="noopener">Anyone shipping production apps or prototypes with Local LLMs on Mobile? What&#39;s the actual use case?</a>
    </h3>

    
    <p class="card-summary">I am primarily interested in knowing what use cases demands running LLMs locally instead of using cloud APIs. Local LLMs have huge latency but complete privacy and I am very interested if any consumer use cases would love privacy over latency &amp;#32; submitted by &amp;#32; /u/mighty-precious2 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r61so4/we_tested_5_vllm_optimizations_prefix_cache_fp8/" target="_blank" rel="noopener">We tested 5 vLLM optimizations: Prefix Cache, FP8, CPU Offload, Disagg P/D, and Sleep Mode</a>
    </h3>

    
    <p class="card-summary">Hi everyone, We just published a new article on the JarvisLabs blog that dives into 5 practical techniques to optimize vLLM performance. https://preview.redd.it/ma65us58ssjg1.png?width=4770&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=63ee465210c7ee2c8eeee1e680bf4af18d5a5717 We actually ran benchmarks on Qwen3-32B to see how much improvements these techniques actually bring to the table. Here is a quick...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/kevin-o-leary-wins-defamation-suit-against-bitboy?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Kevin O‚ÄôLeary wins $2.8M defamation suit against Ben Armstrong</a>
    </h3>

    
    <p class="card-summary">A Miami federal judge has entered a default judgment against Ben Armstrong, who failed to respond to Kevin O‚ÄôLeary‚Äôs complaint accusing him of defamation.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r61pma/with_the_ridiculous_ram_prices_has_anyone_tried/" target="_blank" rel="noopener">With the ridiculous ram prices has anyone tried optane / very fast nvme for page file</a>
    </h3>

    
    <p class="card-summary">I know it&#39;s will be much slower, but I was wondering if anyone explored this path or have insights. &amp;#32; submitted by &amp;#32; /u/AdventurousGold672 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ethereum</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ethereum/comments/1r61oro/daily_general_discussion_february_16_2026/" target="_blank" rel="noopener">Daily General Discussion February 16, 2026</a>
    </h3>

    
    <p class="card-summary">Welcome to the Daily General Discussion on r/ethereum https://imgur.com/3y7vezP Bookmarking this link will always bring you to the current daily: https://old.reddit.com/r/ethereum/about/sticky/?num=2 Please use this thread to discuss Ethereum topics, news, events, and even price! Price discussion posted elsewhere in the subreddit will continue to be removed. As always, be constructive. -...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/artificial</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/artificial/comments/1r61jbw/customizable_ai_companions/" target="_blank" rel="noopener">Customizable AI Companions.</a>
    </h3>

    
    <p class="card-summary">What if, using AI like ChatGPT, Gemini, or Grok, people were able to create real time video calls with their own customizable AI companion? &amp;#32; submitted by &amp;#32; /u/bookgeek210 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r61ir4/agent_vs_humans_hackathon/" target="_blank" rel="noopener">Agent vs Humans Hackathon</a>
    </h3>

    
    <p class="card-summary">Hi everyone, I‚Äôm putting together a new kind of hackathon: the Agent vs Humans Hackathon (Feb 21 - Mar 1). Core goal is to test out how agents can work autonomously at one shot. From Agent&#39;s side - the dev should just single shot the full prompt and the agent runs the entire stuff autonomously. No additional feedback or prompting back. Currently, it is From humans side - Humans is technically...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ChatGPT</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ChatGPT/comments/1r61cl2/chatgpt_warned_me_i_might_accidentally_dox_myself/" target="_blank" rel="noopener">ChatGPT warned me I might accidentally dox myself</a>
    </h3>

    
    <p class="card-summary">So I was using it to help me find a specific extension cord I need (50‚Äô 30A 3-prong dryer cord) &amp;amp; was showing it different options I had found to verify if they were UL listed. I shared a screenshot from my Walmart app &amp;amp; it gave me the warning at the end of its response. Pretty cool, I‚Äôve never seen it do this before. I wonder how standard this behavior is, like if anyone wants to test it...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r619ui/anyone_else_have_problems_where_prompts_just_stop/" target="_blank" rel="noopener">Anyone else have problems where prompts just stop lately?</a>
    </h3>

    
    <p class="card-summary">I pay for this service and it no longer works, web or app, after like 4 queries it just stops responding. It hangs, I press stop and it says it&#39;s an error, if I don&#39;t press stop it will just hang there forever. It&#39;s been like this for two weeks. Is it just me? Is it something with my account? I don&#39;t get it. Should I ask for my money back? &amp;#32; submitted by &amp;#32; /u/bar10dr2 [link] &amp;#32...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">Decrypt</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://decrypt.co/358141/openai-openclaw-founder-lead-push-personal-ai-agents" target="_blank" rel="noopener">OpenAI Taps OpenClaw Founder to Lead Push Into Personal AI Agents</a>
    </h3>

    
    <p class="card-summary">The founder said he is turning OpenClaw into a foundation, calling OpenAI the fastest way to bring open agents to everyone.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r6154q/how_do_you_remove_the_ai_feel_from_generated/" target="_blank" rel="noopener">How do you remove the ‚ÄúAI feel‚Äù from generated textile patterns? (Flux / prompt engineering question)</a>
    </h3>

    
    <p class="card-summary">https://preview.redd.it/qohll9cmlsjg1.png?width=997&amp;amp;format=png&amp;amp;auto=webp&amp;amp;s=9d474eb475fb05ded03591678fc249212df103e7 I‚Äôm generating textile patterns using Flux2 Klein 9B with a custom prompt generator Outputs are compositionally strong and production-ready, but they still carry a recognizable AI fingerprint and AI feel Already tested: Lower prompt verbosity Traditional media styles...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">Decrypt</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://decrypt.co/358138/uk-prime-minister-seeks-new-powers-regulate-ai-chatbots" target="_blank" rel="noopener">UK Prime Minister Seeks New Powers to Regulate AI Chatbots as Child Safety Concerns Mount</a>
    </h3>

    
    <p class="card-summary">The move would bring AI chatbots under UK online safety laws, enabling rapid age limits and feature curbs to protect children.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ChatGPT</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ChatGPT/comments/1r60rr2/first_of_all/" target="_blank" rel="noopener">First of all</a>
    </h3>

    
    <p class="card-summary">&amp;#32; submitted by &amp;#32; /u/hackiv [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r60qu9/ama_announcement_stepfun_ai_the_opensource_lab/" target="_blank" rel="noopener">AMA Announcement: StepFun AI, The Opensource Lab Behind Step-3.5-Flash Model (Thursday, 8AM-11AM PST)</a>
    </h3>

    
    <p class="card-summary">Hi r/LocalLLaMA üëã We&#39;re excited for Thursday&#39;s guests: The StepFun Team! Kicking things off Thursday, Feb. 19th, 8 AM‚Äì11 AM PST ‚ö†Ô∏è Note: The AMA itself will be hosted in a separate thread, please don‚Äôt post questions here. &amp;#32; submitted by &amp;#32; /u/XMasterrrr [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/aave-founder-defi-tokenize-50t-abundance-assets?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Aave founder pitches $50T ‚Äòabundance asset‚Äô boom to drive DeFi</a>
    </h3>

    
    <p class="card-summary">Aave Labs CEO Stani Kulechov said onchain lending could help accelerate the development of solar, energy storage and robotics by putting money behind ‚Äúfuture-proof‚Äù assets.</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/startups</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/startups/comments/1r60jlm/hiringseekingoffering_jobs_cofounders_weekly/" target="_blank" rel="noopener">[Hiring/Seeking/Offering] Jobs / Co-Founders Weekly Thread</a>
    </h3>

    
    <p class="card-summary">[Hiring/Seeking/Offering] Jobs / Co-Founders Weekly Thread This is an experiment. We see there is a demand from the community to: Find Co-Founders Hiring / Seeking Jobs Offering Your Skillset / Looking for Talent Please use the following template: **[SEEKING / HIRING / OFFERING]** (Choose one) **[COFOUNDER / JOB / OFFER]** (Choose one) Company Name: (Optional) Pitch: Preferred Contact Method(s)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12284" target="_blank" rel="noopener">A Lightweight LLM Framework for Disaster Humanitarian Information Classification</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12284v1 Announce Type: new Abstract: Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12285" target="_blank" rel="noopener">From Biased Chatbots to Biased Agents: Examining Role Assignment Effects on LLM Agent Robustness</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12285v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents capable of actions with real-world impacts beyond text generation. While persona-induced biases in text generation are well documented, their effects on agent task performance...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12287" target="_blank" rel="noopener">Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12287v1 Announce Type: new Abstract: End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12302" target="_blank" rel="noopener">Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria \`a Pr\&#39;atica</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12302v1 Announce Type: new Abstract: Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI. This chapter...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12414" target="_blank" rel="noopener">propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12414v1 Announce Type: new Abstract: Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12424" target="_blank" rel="noopener">RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12424v1 Announce Type: new Abstract: Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12445" target="_blank" rel="noopener">RBCorr: Response Bias Correction in Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12445v1 Announce Type: new Abstract: Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12575" target="_blank" rel="noopener">Discovering Semantic Latent Structures in Psychological Scales: A Response-Free Pathway to Efficient Simplification</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12575v1 Announce Type: new Abstract: Psychological scale refinement traditionally relies on response-based methods such as factor analysis, item response theory, and network psychometrics to optimize item composition. Although rigorous, these approaches require large samples and may be...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12635" target="_blank" rel="noopener">Unleashing Low-Bit Inference on Ascend NPUs: A Comprehensive Evaluation of HiFloat Formats</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12635v1 Announce Type: new Abstract: As LLMs scale, low-bit floating-point formats like MXFP and NVFP4 offer new opportunities for precision and efficiency. In this work, we evaluate HiFloat (HiF8 and HiF4), a family of formats tailored for Ascend NPUs. Through rigorous comparison across...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12639" target="_blank" rel="noopener">CLASE: A Hybrid Method for Chinese Legalese Stylistic Evaluation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12639v1 Announce Type: new Abstract: Legal text generated by large language models (LLMs) can usually achieve reasonable factual accuracy, but it frequently fails to adhere to the specialised stylistic norms and linguistic conventions of legal writing. In order to improve stylistic...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12642" target="_blank" rel="noopener">Beyond Normalization: Rethinking the Partition Function as a Difficulty Scheduler for RLVR</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12642v1 Announce Type: new Abstract: Reward-maximizing RL methods enhance the reasoning performance of LLMs, but often reduce the diversity among outputs. Recent works address this issue by adopting GFlowNets, training LLMs to match a target distribution while jointly learning its...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12660" target="_blank" rel="noopener">Learning Ordinal Probabilistic Reward from Preferences</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12660v1 Announce Type: new Abstract: Reward models are crucial for aligning large language models (LLMs) with human values and intentions. Existing approaches follow either Generative (GRMs) or Discriminative (DRMs) paradigms, yet both suffer from limitations: GRMs typically demand...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12674" target="_blank" rel="noopener">$\mathcal{X}$-KD: General Experiential Knowledge Distillation for Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12674v1 Announce Type: new Abstract: Knowledge Distillation (KD) for Large Language Models (LLMs) has become increasingly important as models grow in size and complexity. While existing distillation approaches focus on imitating teacher behavior, they often overlook the original learning...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12705" target="_blank" rel="noopener">MedXIAOHE: A Comprehensive Recipe for Building Medical MLLMs</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12705v1 Announce Type: new Abstract: We present MedXIAOHE, a medical vision-language foundation model designed to advance general-purpose medical understanding and reasoning in real-world clinical applications. MedXIAOHE achieves state-of-the-art performance across diverse medical...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12709" target="_blank" rel="noopener">ReFilter: Improving Robustness of Retrieval-Augmented Generation via Gated Filter</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12709v1 Announce Type: new Abstract: Retrieval-augmented generation (RAG) has become a dominant paradigm for grounding large language models (LLMs) with external evidence in knowledge-intensive question answering. A core design choice is how to fuse retrieved samples into the LLMs, where...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12746" target="_blank" rel="noopener">Lamer-SSL: Layer-aware Mixture of LoRA Experts for Continual Multilingual Expansion of Self-supervised Models without Forgetting</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12746v1 Announce Type: new Abstract: Despite their impressive performance, self-supervised speech models often struggle to generalize to new languages and tend to forget previously acquired knowledge during continual training. To address this, we propose Lamer-SSL, a parameter-efficient...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12759" target="_blank" rel="noopener">Towards a Diagnostic and Predictive Evaluation Methodology for Sequence Labeling Tasks</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12759v1 Announce Type: new Abstract: Standard evaluation in NLP typically indicates that system A is better on average than system B, but it provides little info on how to improve performance and, what is worse, it should not come as a surprise if B ends up being better than A on outside...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12778" target="_blank" rel="noopener">Aspect-Based Sentiment Analysis for Future Tourism Experiences: A BERT-MoE Framework for Persian User Reviews</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12778v1 Announce Type: new Abstract: This study advances aspect-based sentiment analysis (ABSA) for Persian-language user reviews in the tourism domain, addressing challenges of low-resource languages. We propose a hybrid BERT-based model with Top-K routing and auxiliary losses to...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12806" target="_blank" rel="noopener">RAT-Bench: A Comprehensive Benchmark for Text Anonymization</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12806v1 Announce Type: new Abstract: Data containing personal information is increasingly used to train, fine-tune, or query Large Language Models (LLMs). Text is typically scrubbed of identifying information prior to use, often with tools such as Microsoft&#39;s Presidio or Anthropic&#39;s PII...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12811" target="_blank" rel="noopener">Left-right asymmetry in predicting brain activity from LLMs&#39; representations emerges with their formal linguistic competence</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12811v1 Announce Type: new Abstract: When humans and large language models (LLMs) process the same text, activations in the LLMs correlate with brain activity measured, e.g., with functional magnetic resonance imaging (fMRI). Moreover, it has been shown that, as the training of an LLM...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12818" target="_blank" rel="noopener">AIWizards at MULTIPRIDE: A Hierarchical Approach to Slur Reclamation Detection</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12818v1 Announce Type: new Abstract: Detecting reclaimed slurs represents a fundamental challenge for hate speech detection systems, as the same lexcal items can function either as abusive expressions or as in-group affirmations depending on social identity and context. In this work, we...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12871" target="_blank" rel="noopener">MentalBench: A Benchmark for Evaluating Psychiatric Diagnostic Capability of Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12871v1 Announce Type: new Abstract: We introduce MentalBench, a benchmark for evaluating psychiatric diagnostic decision-making in large language models (LLMs). Existing mental health benchmarks largely rely on social media data, limiting their ability to assess DSM-grounded diagnostic...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12889" target="_blank" rel="noopener">BaziQA-Benchmark: Evaluating Symbolic and Temporally Compositional Reasoning in Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12889v1 Announce Type: new Abstract: We present BaziQA-Benchmark, a standardized benchmark for evaluating symbolic and temporally compositional reasoning in large language models. The benchmark is derived from 200 professionally curated, multiple-choice problems from the Global...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12911" target="_blank" rel="noopener">ViMedCSS: A Vietnamese Medical Code-Switching Speech Dataset &amp;amp; Benchmark</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12911v1 Announce Type: new Abstract: Code-switching (CS), which is when Vietnamese speech uses English words like drug names or procedures, is a common phenomenon in Vietnamese medical communication. This creates challenges for Automatic Speech Recognition (ASR) systems, especially in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12921" target="_blank" rel="noopener">When Words Don&#39;t Mean What They Say: Figurative Understanding in Bengali Idioms</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12921v1 Announce Type: new Abstract: Figurative language understanding remains a significant challenge for Large Language Models (LLMs), especially for low-resource languages. To address this, we introduce a new idiom dataset, a large-scale, culturally-grounded corpus of 10,361 Bengali...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12937" target="_blank" rel="noopener">Curriculum Learning and Pseudo-Labeling Improve the Generalization of Multi-Label Arabic Dialect Identification Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12937v1 Announce Type: new Abstract: Being modeled as a single-label classification task for a long time, recent work has argued that Arabic Dialect Identification (ADI) should be framed as a multi-label classification task. However, ADI remains constrained by the availability of...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12966" target="_blank" rel="noopener">ProbeLLM: Automating Principled Diagnosis of LLM Failures</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12966v1 Announce Type: new Abstract: Understanding how and why large language models (LLMs) fail is becoming a central challenge as models rapidly evolve and static evaluations fall behind. While automated probing has been enabled by dynamic test generation, existing approaches often...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12984" target="_blank" rel="noopener">SciAgentGym: Benchmarking Multi-Step Scientific Tool-use in LLM Agents</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12984v1 Announce Type: new Abstract: Scientific reasoning inherently demands integrating sophisticated toolkits to navigate domain-specific knowledge. Yet, current benchmarks largely overlook agents&#39; ability to orchestrate tools for such rigorous workflows. To bridge this gap, we...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12989" target="_blank" rel="noopener">Evaluating the Homogeneity of Keyphrase Prediction Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12989v1 Announce Type: new Abstract: Keyphrases which are useful in several NLP and IR applications are either extracted from text or predicted by generative models. Contrarily to keyphrase extraction approaches, keyphrase generation models can predict keyphrases that do not appear in a...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12996" target="_blank" rel="noopener">Know More, Know Clearer: A Meta-Cognitive Framework for Knowledge Augmentation in Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12996v1 Announce Type: new Abstract: Knowledge augmentation has significantly enhanced the performance of Large Language Models (LLMs) in knowledge-intensive tasks. However, existing methods typically operate on the simplistic premise that model performance equates with internal...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13047" target="_blank" rel="noopener">Can we trust AI to detect healthy multilingual English speakers among the cognitively impaired cohort in the UK? An investigation using real-world conversational speech</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13047v1 Announce Type: new Abstract: Conversational speech often reveals early signs of cognitive decline, such as dementia and MCI. In the UK, one in four people belongs to an ethnic minority, and dementia prevalence is expected to rise most rapidly among Black and Asian communities...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13059" target="_blank" rel="noopener">TraceBack: Multi-Agent Decomposition for Fine-Grained Table Attribution</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13059v1 Announce Type: new Abstract: Question answering (QA) over structured tables requires not only accurate answers but also transparency about which cells support them. Existing table QA systems rarely provide fine-grained attribution, so even correct answers often lack verifiable...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13084" target="_blank" rel="noopener">Exploring a New Competency Modeling Process with Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13084v1 Announce Type: new Abstract: Competency modeling is widely used in human resource management to select, develop, and evaluate talent. However, traditional expert-driven approaches rely heavily on manual analysis of large volumes of interview transcripts, making them costly and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13102" target="_blank" rel="noopener">Towards interpretable models for language proficiency assessment: Predicting the CEFR level of Estonian learner texts</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13102v1 Announce Type: new Abstract: Using NLP to analyze authentic learner language helps to build automated assessment and feedback tools. It also offers new and extensive insights into the development of second language production. However, there is a lack of research explicitly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13110" target="_blank" rel="noopener">SCOPE: Selective Conformal Optimized Pairwise LLM Judging</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13110v1 Announce Type: new Abstract: Large language models (LLMs) are increasingly used as judges to replace costly human preference labels in pairwise evaluation. Despite their practicality, LLM judges remain prone to miscalibration and systematic biases. This paper proposes SCOPE...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13123" target="_blank" rel="noopener">From sunblock to softblock: Analyzing the correlates of neology in published writing and on social media</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13123v1 Announce Type: new Abstract: Living languages are shaped by a host of conflicting internal and external evolutionary pressures. While some of these pressures are universal across languages and cultures, others differ depending on the social and conversational context: language...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13139" target="_blank" rel="noopener">OpenLID-v3: Improving the Precision of Closely Related Language Identification -- An Experience Report</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13139v1 Announce Type: new Abstract: Language identification (LID) is an essential step in building high-quality multilingual datasets from web data. Existing LID tools (such as OpenLID or GlotLID) often struggle to identify closely related languages and to distinguish valid natural...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13194" target="_blank" rel="noopener">Semantic Chunking and the Entropy of Natural Language</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13194v1 Announce Type: new Abstract: The entropy rate of printed English is famously estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only recently approached. This entropy rate implies that English contains nearly 80 percent...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12286" target="_blank" rel="noopener">Alignment or Integration? Rethinking Multimodal Fusion in DNA-language Foundation Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12286v1 Announce Type: cross Abstract: Fusing DNA foundation models with large language models (LLMs) for DNA-language reasoning raises a fundamental question: at what level should genomic sequences and natural language interact? Most existing approaches encode DNA sequences and text...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12301" target="_blank" rel="noopener">Beyond Musical Descriptors: Extracting Preference-Bearing Intent in Music Queries</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12301v1 Announce Type: cross Abstract: Although annotated music descriptor datasets for user queries are increasingly common, few consider the user&#39;s intent behind these descriptors, which is essential for effectively meeting their needs. We introduce MusicRecoIntent, a manually...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12316" target="_blank" rel="noopener">GT-HarmBench: Benchmarking AI Safety Risks Through the Lens of Game Theory</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12316v1 Announce Type: cross Abstract: Frontier AI systems are increasingly capable and deployed in high-stakes multi-agent environments. However, existing AI safety benchmarks largely evaluate single agents, leaving multi-agent risks such as coordination failure and conflict poorly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12389" target="_blank" rel="noopener">Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12389v1 Announce Type: cross Abstract: Temporal knowledge graph (TKG) forecasting requires predicting future facts by jointly modeling structural dependencies within each snapshot and temporal evolution across snapshots. However, most existing methods are stateless: they recompute entity...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12418" target="_blank" rel="noopener">Sparse Autoencoders are Capable LLM Jailbreak Mitigators</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12418v1 Announce Type: cross Abstract: Jailbreak attacks remain a persistent threat to large language model safety. We propose Context-Conditioned Delta Steering (CC-Delta), an SAE-based defense that identifies jailbreak-relevant sparse features by comparing token-level representations...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12526" target="_blank" rel="noopener">Constraint-Rectified Training for Efficient Chain-of-Thought</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12526v1 Announce Type: cross Abstract: Chain-of-Thought (CoT) has significantly enhanced the reasoning capabilities of Large Language Models (LLMs), especially when combined with reinforcement learning (RL) based post-training methods. While longer reasoning traces can improve answer...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12528" target="_blank" rel="noopener">DiffuRank: Effective Document Reranking with Diffusion Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12528v1 Announce Type: cross Abstract: Recent advances in large language models (LLMs) have inspired new paradigms for document reranking. While this paradigm better exploits the reasoning and contextual understanding capabilities of LLMs, most existing LLM-based rerankers rely on...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12546" target="_blank" rel="noopener">Decoder-only Conformer with Modality-aware Sparse Mixtures of Experts for ASR</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12546v1 Announce Type: cross Abstract: We present a decoder-only Conformer for automatic speech recognition (ASR) that processes speech and text in a single stack without external speech encoders or pretrained large language models (LLM). The model uses a modality-aware sparse mixture of...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12601" target="_blank" rel="noopener">HyperMLP: An Integrated Perspective for Sequence Modeling</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12601v1 Announce Type: cross Abstract: Self-attention is often viewed as probabilistic query-key lookup, motivating designs that preserve normalized attention scores and fixed positional semantics. We advocate a simpler and more unified perspective: an autoregressive attention head can...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12618" target="_blank" rel="noopener">Vision Token Reduction via Attention-Driven Self-Compression for Efficient Multimodal Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12618v1 Announce Type: cross Abstract: Multimodal Large Language Models (MLLMs) incur significant computational cost from processing numerous vision tokens through all LLM layers. Prior pruning methods operate either before the LLM, limiting generality due to diverse encoder-projector...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12662" target="_blank" rel="noopener">Think Fast and Slow: Step-Level Cognitive Depth Adaptation for LLM Agents</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12662v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly deployed as autonomous agents for multi-turn decision-making tasks. However, current agents typically rely on fixed cognitive patterns: non-thinking models generate immediate responses, while thinking...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12735" target="_blank" rel="noopener">VimRAG: Navigating Massive Visual Context in Retrieval-Augmented Generation via Multimodal Memory Graph</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12735v1 Announce Type: cross Abstract: Effectively retrieving, reasoning, and understanding multimodal information remains a critical challenge for agentic systems. Traditional Retrieval-augmented Generation (RAG) methods rely on linear interaction histories, which struggle to handle...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12881" target="_blank" rel="noopener">Semantic Communities and Boundary-Spanning Lyrics in K-pop: A Graph-Based Unsupervised Analysis</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12881v1 Announce Type: cross Abstract: Large-scale lyric corpora present unique challenges for data-driven analysis, including the absence of reliable annotations, multilingual content, and high levels of stylistic repetition. Most existing approaches rely on supervised classification...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12892" target="_blank" rel="noopener">RADAR: Revealing Asymmetric Development of Abilities in MLLM Pre-training</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12892v1 Announce Type: cross Abstract: Pre-trained Multi-modal Large Language Models (MLLMs) provide a knowledge-rich foundation for post-training by leveraging their inherent perception and reasoning capabilities to solve complex tasks. However, the lack of an efficient evaluation...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.12968" target="_blank" rel="noopener">RGAlign-Rec: Ranking-Guided Alignment for Latent Query Reasoning in Recommendation Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.12968v1 Announce Type: cross Abstract: Proactive intent prediction is a critical capability in modern e-commerce chatbots, enabling &#34;zero-query&#34; recommendations by anticipating user needs from behavioral and contextual signals. However, existing industrial systems face two fundamental...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13028" target="_blank" rel="noopener">Human-Aligned MLLM Judges for Fine-Grained Image Editing Evaluation: A Benchmark, Framework, and Analysis</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13028v1 Announce Type: cross Abstract: Evaluating image editing models remains challenging due to the coarse granularity and limited interpretability of traditional metrics, which often fail to capture aspects important to human perception and intent. Such metrics frequently reward...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13033" target="_blank" rel="noopener">Buy versus Build an LLM: A Decision Framework for Governments</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13033v1 Announce Type: cross Abstract: Large Language Models (LLMs) represent a new frontier of digital infrastructure that can support a wide range of public-sector applications, from general purpose citizen services to specialized and sensitive state functions. When expanding AI...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13035" target="_blank" rel="noopener">Look Inward to Explore Outward: Learning Temperature Policy from LLM Internal States via Hierarchical RL</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13035v1 Announce Type: cross Abstract: Reinforcement Learning from Verifiable Rewards (RLVR) trains large language models (LLMs) from sampled trajectories, making decoding strategy a core component of learning rather than a purely inference-time choice. Sampling temperature directly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13069" target="_blank" rel="noopener">Memory-Efficient Structured Backpropagation for On-Device LLM Fine-Tuning</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13069v1 Announce Type: cross Abstract: On-device fine-tuning enables privacy-preserving personalization of large language models, but mobile devices impose severe memory constraints, typically 6--12GB shared across all workloads. Existing approaches force a trade-off between exact...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13073" target="_blank" rel="noopener">LCSB: Layer-Cyclic Selective Backpropagation for Memory-Efficient On-Device LLM Fine-Tuning</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13073v1 Announce Type: cross Abstract: Memory-efficient backpropagation (MeBP) has enabled first-order fine-tuning of large language models (LLMs) on mobile devices with less than 1GB memory. However, MeBP requires backward computation through all transformer layers at every step, where...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13093" target="_blank" rel="noopener">Consistency of Large Reasoning Models Under Multi-Turn Attacks</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13093v1 Announce Type: cross Abstract: Large reasoning models with reasoning capabilities achieve state-of-the-art performance on complex tasks, but their robustness under multi-turn adversarial pressure remains underexplored. We evaluate nine frontier reasoning models under adversarial...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13151" target="_blank" rel="noopener">Quantization-Robust LLM Unlearning via Low-Rank Adaptation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13151v1 Announce Type: cross Abstract: Large Language Model (LLM) unlearning aims to remove targeted knowledge from a trained model, but practical deployments often require post-training quantization (PTQ) for efficient inference. However, aggressive low-bit PTQ can mask or erase...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.13191" target="_blank" rel="noopener">CoPE-VideoLM: Codec Primitives For Efficient Video Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.13191v1 Announce Type: cross Abstract: Video Language Models (VideoLMs) empower AI systems to understand temporal dynamics in videos. To fit to the maximum context window constraint, current methods use keyframe sampling which can miss both macro-level events and micro-level details due...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2404.08567" target="_blank" rel="noopener">CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal Model Inference</a>
    </h3>

    
    <p class="card-summary">arXiv:2404.08567v2 Announce Type: replace Abstract: In response to the rising interest in large multimodal models, we introduce Cross-Attention Token Pruning (CATP), a precision-focused token pruning method. Our approach leverages cross-attention layers in multimodal models, exemplified by BLIP-2...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2504.01342" target="_blank" rel="noopener">Foundations and Evaluations in NLP</a>
    </h3>

    
    <p class="card-summary">arXiv:2504.01342v2 Announce Type: replace Abstract: This memoir explores two fundamental aspects of Natural Language Processing (NLP): the creation of linguistic resources and the evaluation of NLP system performance. Over the past decade, my work has focused on developing a morpheme-based...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2504.07282" target="_blank" rel="noopener">RAISE: Reinforced Adaptive Instruction Selection For Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2504.07282v5 Announce Type: replace Abstract: In the instruction fine-tuning of large language models (LLMs), it is widely recognized that a few high-quality instructions are superior to a large number of low-quality instructions. At present, many instruction selection methods have been...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2504.17052" target="_blank" rel="noopener">PReSS: A Black-Box Framework for Evaluating Political Stance Stability in LLMs via Argumentative Pressure</a>
    </h3>

    
    <p class="card-summary">arXiv:2504.17052v3 Announce Type: replace Abstract: Existing evaluations of political bias in large language models (LLMs) typically classify outputs as left- or right-leaning. We extend this perspective by examining how ideological tendencies vary across topics and how consistently models maintain...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.02872" target="_blank" rel="noopener">Highlight &amp;amp; Summarize: RAG without the jailbreaks</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.02872v2 Announce Type: replace Abstract: Preventing jailbreaking and model hijacking of Large Language Models (LLMs) is an important yet challenging task. When interacting with a chatbot, malicious users can input specially crafted prompts that cause the LLM to generate undesirable...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.08236" target="_blank" rel="noopener">Exploring Safety Alignment Evaluation of LLMs in Chinese Mental Health Dialogues via LLM-as-Judge</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.08236v2 Announce Type: replace Abstract: Evaluating the safety alignment of LLM responses in high-risk mental health dialogues is particularly difficult due to missing gold-standard answers and the ethically sensitive nature of these interactions. To address this challenge, we propose...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.08275" target="_blank" rel="noopener">MLLM-CTBench: A Benchmark for Continual Instruction Tuning with Reasoning Process Diagnosis</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.08275v3 Announce Type: replace Abstract: Continual instruction tuning(CIT) during the post-training phase is crucial for adapting multimodal large language models (MLLMs) to evolving real-world demands. However, the progress is hampered by the lack of benchmarks with rigorous...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.12685" target="_blank" rel="noopener">ToolACE-MT: Non-Autoregressive Generation for Agentic Multi-Turn Interaction</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.12685v3 Announce Type: replace Abstract: Agentic task-solving with Large Language Models (LLMs) requires multi-turn, multi-step interactions, often involving complex function calls and dynamic user-agent exchanges. Existing simulation-based data generation methods for such scenarios rely...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.16371" target="_blank" rel="noopener">The Mediomatix Corpus: Parallel Data for Romansh Language Varieties via Comparable Schoolbooks</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.16371v2 Announce Type: replace Abstract: The five idioms (i.e., varieties) of the Romansh language are largely standardized and are taught in the schools of the respective communities in Switzerland. In this paper, we present the first parallel corpus of Romansh idioms. The corpus is...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2509.17688" target="_blank" rel="noopener">TASO: Task-Aligned Sparse Optimization for Parameter-Efficient Model Adaptation</a>
    </h3>

    
    <p class="card-summary">arXiv:2509.17688v2 Announce Type: replace Abstract: LoRA has become one of the most widely used parameter-efficient fine-tuning methods due to its simplicity and effectiveness. However, numerous studies have shown that LoRA often introduces substantial parameter redundancy, which not only increases...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.22747" target="_blank" rel="noopener">Low-Resource Dialect Adaptation of Large Language Models: A French Dialect Case-Study</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.22747v2 Announce Type: replace Abstract: Despite the widespread adoption of large language models (LLMs), their strongest capabilities remain largely confined to a small number of high-resource languages for which there is abundant training data. Recently, continual pre-training (CPT)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.10453" target="_blank" rel="noopener">Reasoning about Intent for Ambiguous Requests</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.10453v2 Announce Type: replace Abstract: Large language models often respond to ambiguous requests by implicitly committing to one interpretation. Intent misunderstandings can frustrate users and create safety risks. To address this, we propose generating multiple interpretation-answer...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2512.15052" target="_blank" rel="noopener">SGM: Safety Glasses for Multimodal Large Language Models via Neuron-Level Detoxification</a>
    </h3>

    
    <p class="card-summary">arXiv:2512.15052v3 Announce Type: replace Abstract: Disclaimer: Samples in this paper may be harmful and cause discomfort. Multimodal large language models (MLLMs) enable multimodal generation but inherit toxic, biased, and NSFW signals from weakly curated pretraining corpora, causing safety risks...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.09725" target="_blank" rel="noopener">Assessing and Improving Punctuation Robustness in English-Marathi Machine Translation</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.09725v3 Announce Type: replace Abstract: Neural Machine Translation (NMT) systems rely heavily on explicit punctuation cues to resolve semantic ambiguities in a source sentence. Inputting user-generated sentences, which are likely to contain missing or incorrect punctuation, results in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.14249" target="_blank" rel="noopener">Which Reasoning Trajectories Teach Students to Reason Better? A Simple Metric of Informative Alignment</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.14249v3 Announce Type: replace Abstract: Long chain-of-thought (CoT) trajectories provide rich supervision signals for distilling reasoning from teacher to student LLMs. However, both prior work and our experiments show that trajectories from stronger teachers do not necessarily yield...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.22620" target="_blank" rel="noopener">Layer-wise Swapping for Generalizable Multilingual Safety</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.22620v2 Announce Type: replace Abstract: Despite the rapid advancements of Large Language Models (LLMs), safety risks remain a critical challenge for low-resource languages. Existing safety datasets are predominantly English centric, limiting progress in multilingual safety alignment. As...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.04884" target="_blank" rel="noopener">Reinforced Attention Learning</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.04884v2 Announce Type: replace Abstract: Post-training with Reinforcement Learning (RL) has substantially improved reasoning in Large Language Models (LLMs) via test-time scaling. However, extending this paradigm to Multimodal LLMs (MLLMs) through verbose rationales yields limited gains...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.07621" target="_blank" rel="noopener">SciClaimEval: Cross-modal Claim Verification in Scientific Papers</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.07621v2 Announce Type: replace Abstract: We present SciClaimEval, a new scientific dataset for the claim verification task. Unlike existing resources, SciClaimEval features authentic claims, including refuted ones, directly extracted from published papers. To create refuted claims, we...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.08543" target="_blank" rel="noopener">GISA: A Benchmark for General Information-Seeking Assistant</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.08543v2 Announce Type: replace Abstract: The advancement of large language models (LLMs) has significantly accelerated the development of search agents capable of autonomously gathering information through multi-turn web interactions. Various benchmarks have been proposed to evaluate...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2503.22968" target="_blank" rel="noopener">Redefining Evaluation Standards: A Unified Framework for Evaluating the Korean Capabilities of Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2503.22968v5 Announce Type: replace-cross Abstract: Recent advancements in Korean large language models (LLMs) have driven numerous benchmarks and evaluation methods, yet inconsistent protocols cause up to 10 p.p performance gaps across institutions. Overcoming these reproducibility gaps does...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2504.12579" target="_blank" rel="noopener">Provable Secure Steganography Based on Adaptive Dynamic Sampling</a>
    </h3>

    
    <p class="card-summary">arXiv:2504.12579v3 Announce Type: replace-cross Abstract: The security of private communication is increasingly at risk due to widespread surveillance. Steganography, a technique for embedding secret messages within innocuous carriers, enables covert communication over monitored channels. Provably...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.05004" target="_blank" rel="noopener">R-Zero: Self-Evolving Reasoning LLM from Zero Data</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.05004v4 Announce Type: replace-cross Abstract: Self-evolving Large Language Models (LLMs) offer a scalable path toward super-intelligence by autonomously generating, refining, and learning from their own experiences. However, existing methods for training such models still rely heavily...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2509.25889" target="_blank" rel="noopener">Multimodal LLM With Hierarchical Mixture-of-Experts for VQA on 3D Brain MRI</a>
    </h3>

    
    <p class="card-summary">arXiv:2509.25889v3 Announce Type: replace-cross Abstract: Multiparametric 3D brain MRI (mpMRI) is central to neuroradiology, but producing tumor location, appearance, size, and involvement of critical structures for neurosurgical planning remains challenging. We introduce mpLLM, a multimodal LLM...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.07978" target="_blank" rel="noopener">VoiceAgentBench: Are Voice Assistants ready for agentic tasks?</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.07978v3 Announce Type: replace-cross Abstract: Large scale Speech Language Models have enabled voice assistants capable of understanding natural spoken queries and performing complex tasks. However, existing speech benchmarks largely focus on isolated capabilities such as transcription...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.11834" target="_blank" rel="noopener">Don&#39;t Walk the Line: Boundary Guidance for Filtered Generation</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.11834v2 Announce Type: replace-cross Abstract: Generative models are increasingly paired with safety classifiers that filter harmful or undesirable outputs. A common strategy is to fine-tune the generator to reduce the probability of being filtered, but this can be suboptimal: it often...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.00004" target="_blank" rel="noopener">Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.00004v2 Announce Type: replace-cross Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.12447" target="_blank" rel="noopener">Privacy-Preserving Federated Learning with Verifiable Fairness Guarantees</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.12447v2 Announce Type: replace-cross Abstract: Federated learning enables collaborative model training across distributed institutions without centralizing sensitive data; however, ensuring algorithmic fairness across heterogeneous data distributions while preserving privacy remains...</p>
    

    
</article>
    
</div>


    </main>

    <footer class="site-footer">
        <div class="container">
            <p>Last updated: February 16, 2026 at 07:39 UTC</p>
            <p>493 articles from 19 sources</p>
            <p>Daily Signal Feed &mdash; AI, Web3 &amp; Emerging Tech Aggregator</p>
        </div>
    </footer>

    <script>
    // Client-side search filter
    document.addEventListener('DOMContentLoaded', function() {
        const searchBar = document.querySelector('.search-bar');
        if (searchBar) {
            searchBar.addEventListener('input', function(e) {
                const query = e.target.value.toLowerCase();
                const cards = document.querySelectorAll('.article-card, .archive-item');
                cards.forEach(function(card) {
                    const text = card.textContent.toLowerCase();
                    card.style.display = text.includes(query) ? '' : 'none';
                });
            });
        }
    });
    </script>
</body>
</html>