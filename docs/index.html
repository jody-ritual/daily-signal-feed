<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Signal Feed — AI, Web3 & Emerging Trends</title>
    <link rel="stylesheet" href="/daily-signal-feed/css/style.css">
    <meta name="description" content="AI, Web3, and emerging tech news aggregated from 50+ sources with trend detection.">
</head>
<body>
    <header class="site-header">
        <div class="container header-inner">
            <a href="/daily-signal-feed/" class="site-logo">
                <h1>Daily Signal Feed</h1>
                <span class="tagline">AI &bull; Web3 &bull; Emerging Trends</span>
            </a>
            <nav class="main-nav">
                <a href="/daily-signal-feed/" class="active">Home</a>
                
                <a href="/daily-signal-feed/category/ai-llms.html"
                   class="">
                    AI &amp; LLMs (368)
                </a>
                
                <a href="/daily-signal-feed/category/web3-defi.html"
                   class="">
                    Web3 &amp; DeFi (17)
                </a>
                
                <a href="/daily-signal-feed/category/deals.html"
                   class="">
                    Deals &amp; Acquisitions (6)
                </a>
                
                <a href="/daily-signal-feed/category/new-tools.html"
                   class="">
                    New Tools &amp; Apps (8)
                </a>
                
                <a href="/daily-signal-feed/category/regulation.html"
                   class="">
                    Regulation &amp; Policy
                </a>
                
                <a href="/daily-signal-feed/category/social-buzz.html"
                   class="">
                    Social Buzz (46)
                </a>
                
                <a href="/daily-signal-feed/category/emerging-trends.html"
                   class="">
                    Emerging Trends
                </a>
                
                <a href="/daily-signal-feed/archive.html" class="">Archive</a>
            </nav>
        </div>
    </header>

    <main class="container">
        
<!-- Executive Summary -->
<section class="exec-summary">
    <h2>Signal Summary</h2>

    <div class="summary-grid">
        <!-- Trending Topics -->
        <div class="summary-card">
            <h3>Trending Now</h3>
            <ul class="trend-list">
                
                <li class="trend-item">
                    <span class="trend-term">Kalshi</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Evaluating</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Neural</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">6 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Agent Systems</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Accurate</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">HN</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">8 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">GNN</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">9 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
            </ul>
        </div>

        <!-- Category Activity -->
        <div class="summary-card">
            <h3>Category Activity</h3>
            <div class="cat-bars">
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">AI &amp; LLMs</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 100%; background: #4F46E5;"></div>
                    </div>
                    <span class="cat-bar-count">368</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Social Buzz</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 12%; background: #06B6D4;"></div>
                    </div>
                    <span class="cat-bar-count">46</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Web3 &amp; DeFi</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 5%; background: #8B5CF6;"></div>
                    </div>
                    <span class="cat-bar-count">17</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">New Tools &amp; Apps</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 2%; background: #F59E0B;"></div>
                    </div>
                    <span class="cat-bar-count">8</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Deals &amp; Acquisitions</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 2%; background: #EC4899;"></div>
                    </div>
                    <span class="cat-bar-count">6</span>
                </div>
                
                
                
                
                
                
            </div>
        </div>

        <!-- Stats -->
        <div class="summary-card">
            <h3>Today's Signal</h3>
            <div class="stat-grid">
                <div class="stat-item">
                    <div class="stat-value">445</div>
                    <div class="stat-label">Articles</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">22</div>
                    <div class="stat-label">Sources</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">18</div>
                    <div class="stat-label">Trending</div>
                </div>
                <div class="stat-item">
                    <span class="momentum-badge momentum-accelerating">
                        accelerating
                    </span>
                    <div class="stat-label">Momentum</div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Search -->
<input type="text" class="search-bar" placeholder="Search articles by title, source, or keyword..." aria-label="Search articles">

<!-- Trending Articles -->

<section>
    <div class="section-header">
        <h2>Trending Now</h2>
    </div>
    <div class="article-grid">
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/SideProject</span>
        <span class="card-category" style="background: #F59E0B;">
            New Tools &amp; Apps
        </span>
        <span class="card-time">13m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/SideProject/comments/1r7wg77/i_built_this_and_it_actually_works/" target="_blank" rel="noopener">I built this and it actually works.</a>
    </h3>

    
    <p class="card-summary">Hey everyone, Just shipped an app I’ve been working on called Stylme. It’s basically an AI stylist, you can recreate celebrity outfits or generate fits from a photo. Built the whole thing with React Native on the frontend, Go on the backend, and running on GCP with Cloud Run + Spanner. Using image generation + vision models under the hood, and RevenueCat for subs. Honestly the biggest learning...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/nevada-sues-kalshi-after-prediction-market-loses-bid-to-stop-state-action?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Nevada sues Kalshi after prediction market loses bid to stop state action</a>
    </h3>

    
    <p class="card-summary">Kalshi is looking to have Nevada’s lawsuit heard in federal court, again asserting it is subject only to federal commodity exchange laws.</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15509" target="_blank" rel="noopener">Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15509v1 Announce Type: new Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15547" target="_blank" rel="noopener">jina-embeddings-v5-text: Task-Targeted Embedding Distillation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15547v1 Announce Type: new Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15778" target="_blank" rel="noopener">*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15778v1 Announce Type: new Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.19919" target="_blank" rel="noopener">Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.19919v2 Announce Type: replace Abstract: While stereotypes are well-documented in human social interactions, AI systems are often presumed to be less susceptible to such biases. Previous studies have focused on biases inherited from training data, but whether stereotypes can emerge...</p>
    

    
</article>
        
    </div>
</section>


<!-- Latest by Date -->

<h3 class="date-label">February 18, 2026</h3>
<div class="article-grid">
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/SideProject</span>
        <span class="card-category" style="background: #F59E0B;">
            New Tools &amp; Apps
        </span>
        <span class="card-time">13m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/SideProject/comments/1r7wg77/i_built_this_and_it_actually_works/" target="_blank" rel="noopener">I built this and it actually works.</a>
    </h3>

    
    <p class="card-summary">Hey everyone, Just shipped an app I’ve been working on called Stylme. It’s basically an AI stylist, you can recreate celebrity outfits or generate fits from a photo. Built the whole thing with React Native on the frontend, Go on the backend, and running on GCP with Cloud Run + Spanner. Using image generation + vision models under the hood, and RevenueCat for subs. Honestly the biggest learning...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">15m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r7wfiq/what_kind_of_a_promt_would_help_me_to_do_the_job/" target="_blank" rel="noopener">What kind of a promt would help me to do the job?</a>
    </h3>

    
    <p class="card-summary">I am trying to do a clothing marketting image by making the newborn clothing set got worn by a baby but its always en up as a mess because of the words and white part at the chest. https://preview.redd.it/hzck0sexe7kg1.jpg?width=4000&amp;amp;format=pjpg&amp;amp;auto=webp&amp;amp;s=056b07c51d109d3a1438059d68769caf6c7711c9...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/SideProject</span>
        <span class="card-category" style="background: #F59E0B;">
            New Tools &amp; Apps
        </span>
        <span class="card-time">16m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/SideProject/comments/1r7weeo/wenn_du_das_ignorierst_verlierst_du_jeden_tag/" target="_blank" rel="noopener">Wenn du das ignorierst, verlierst du jeden Tag Stunden.</a>
    </h3>

    
    <p class="card-summary">Wenn du das ignorierst, verlierst du jeden Tag Stunden. Du arbeitest. Du klickst. Du suchst. Du wiederholst. Jeden Tag? Die meisten merken es nicht einmal. Sie arbeiten mehr. Sie klicken mehr. Sie verschwenden mehr Zeit. Nicht weil sie müssen. Sondern weil sie die Lösung nicht kennen. Ein einziger Prompt kann dir täglich Stunden zurückgeben. Nicht einmalig. Sondern für immer. Die Frage ist nicht...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">17m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r7we6g/my_account_was_flagged_for_potentially_highrisk/" target="_blank" rel="noopener">My account was flagged for potentially high-risk cyber activity (PRO PLAN)</a>
    </h3>

    
    <p class="card-summary">Hello, I have a problem. I&#39;m making a game in Godot that is hacker-style, but today, out of nowhere, Codex started writing this: &amp;quot;Your account was flagged for potentially high-risk cyber activity and this request was routed to gpt-5.2 as a fallback. To regain access to gpt-5.3-codex, apply for trusted access: https://chatgpt.com/cyber or learn more...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">32m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/18/bitcoin-losing-usd70-000-is-a-warning-sign-for-further-downside" target="_blank" rel="noopener">Bitcoin losing $70,000 is a warning sign for further downside</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">Hacker News - Front Page</span>
        <span class="card-category" style="background: #F59E0B;">
            New Tools &amp; Apps
        </span>
        <span class="card-time">38m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://paraschopra.github.io/explainers/" target="_blank" rel="noopener">Show HN: Beautiful interactive explainers generated with Claude Code</a>
    </h3>

    
    <p class="card-summary">Hello HN, Recently an amazingly beautiful explainer was shared on HN: https://explainers.blog/posts/why-is-the-sky-blue/ I loved it so much that I wished more topics were explained that way. So, I decided to stress-test today&#39;s frontier models (Opus 4.6 in Claude Code) to generate similar explainer...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/artificial</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">38m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/artificial/comments/1r7w1o3/ai_summit_19th_feb/" target="_blank" rel="noopener">AI summit (19th feb)</a>
    </h3>

    
    <p class="card-summary">Going to attend AI Summit on 19th feb in Delhi, Anyone is going on the same day please connect, going alone need a company. Thanks Connect over DM. &amp;#32; submitted by &amp;#32; /u/PerformanceSavings52 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">41m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/18/peter-thiel-dumps-all-his-stock-in-ether-treasury-firm-ethzilla" target="_blank" rel="noopener">Peter Thiel&#39;s Founders Fund dumps every ETHZilla share</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">41m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r7vzm6/ugh_so_apparently_im_a_cyber_threat/" target="_blank" rel="noopener">Ugh. So apparently I’m a “cyber threat”</a>
    </h3>

    
    <p class="card-summary">Ran an update on Codex today, then launched the app and asked it to execute the next step in our project plan. It hallucinated completely false next set of steps - so I asked it where those instructions came from. Boom. Account flagged for “high-risk cyber activity” for… working on a weather prediction model. Now they are going to permanent reroute my activity to suboptimal models unless I give...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/artificial</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">48m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/artificial/comments/1r7vvdp/sony_group_tech_can_identify_original_music_in/" target="_blank" rel="noopener">Sony Group tech can identify original music in AI-generated songs</a>
    </h3>

    
    <p class="card-summary">&amp;#32; submitted by &amp;#32; /u/esporx [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/defi</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">56m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/defi/comments/1r7vqaj/moonwell_hack_shows_new_defi_risk_aigenerated/" target="_blank" rel="noopener">Moonwell hack shows new DeFi risk: AI-generated oracle bug</a>
    </h3>

    
    <p class="card-summary">Moonwell lost about $1.78M after a pricing oracle bug mispriced cbETH at ~$1.12 instead of ~$2200. What makes this case different: the faulty oracle logic was reportedly generated by an AI model during development. So this wasn’t a classic oracle manipulation or flash-loan attack — it was a code-level valuation error baked into the contract. As AI-assisted smart-contract development grows, this...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/web3</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/web3/comments/1r7vj1x/modular_vs_monolithic_i_chose_eth_what_do_you/" target="_blank" rel="noopener">Modular vs Monolithic, I chose ETH. What do you think?</a>
    </h3>

    
    <p class="card-summary">Hey everyone, quick architecture debate. Two visions: Ethereum: a rock-solid L1 + L2s to scale (modular) Solana: everything on L1 for performance and a simpler UX (monolithic) Personally, I’ve chosen ETH, mainly for the security/neutrality base layer and the idea of a coherent L1+L2 platform that can scale cleanly over time. Curious to hear your takes: Which approach do you think will dominate in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/startups</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/startups/comments/1r7vgkn/client_asking_for_penetration_test_i_will_not/" target="_blank" rel="noopener">Client asking for Penetration Test. I will not promote</a>
    </h3>

    
    <p class="card-summary">We&#39;re a small 2-man group based out of Idaho doing work in retail ad space. We&#39;re we&#39;re shoring up our online platform, when people ask for penetration test -- what do you expect from them? I know SOC 2 Type 2 will take a while but what would you recommend for Pen Testing? Not sure which type of test to get or what to expect. &amp;#32; submitted by &amp;#32; /u/beethoven1827 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/cryptocurrency</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/CryptoCurrency/comments/1r7vexz/thinking_of_moving_some_funds_to_uex_us_any/" target="_blank" rel="noopener">Thinking of moving some funds to UEX US - any active traders here?</a>
    </h3>

    
    <p class="card-summary">I’ve been looking at UEX US lately. The interface seems decent, but I’m skeptical about the actual liquidity &amp;quot;under the hood&amp;quot; for mid-caps. Before I commit a larger part of my portfolio, has anyone actually traded there recently? Specifically: How’s the slippage on $5k+ orders? (not for BTC/ETH, but the smaller pairs). Are withdrawals instant or do they hold funds for &amp;quot;manual...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/nevada-sues-kalshi-after-prediction-market-loses-bid-to-stop-state-action?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Nevada sues Kalshi after prediction market loses bid to stop state action</a>
    </h3>

    
    <p class="card-summary">Kalshi is looking to have Nevada’s lawsuit heard in federal court, again asserting it is subject only to federal commodity exchange laws.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/4-data-points-suggest-xrp-price-bottomed-at-dollar1-12-are-bulls-ready-to-take-over?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">4 data points suggest XRP price bottomed at $1.12: Are bulls ready to take over?</a>
    </h3>

    
    <p class="card-summary">Multiple technical, onchain and exchange-traded product data points suggest $1.12 was the generational bottom for XRP. Is it time for a trend reversal?</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/18/bitcoin-etfs-hold-billions-after-price-crash-but-resilience-masks-harsh-reality" target="_blank" rel="noopener">Bitcoin ETFs hold billions despite price crash, but resilience masks harsh reality</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/MachineLearning</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/MachineLearning/comments/1r7v6dh/r_ksplanifolds_advancing_general_purpose/" target="_blank" rel="noopener">[R] K-Splanifolds: Advancing General Purpose Regression with Linear-Time Parametric Spline Manifolds</a>
    </h3>

    
    <p class="card-summary">I cooked up a new fast geometric regression algorithm and show that it is a suitable replacement for MLPs. Check out the paper: https://doi.org/10.5281/zenodo.18673034 Whats inside? New research indicates that many representations within LLMs create geometric structures to model language. ( https://arxiv.org/abs/2601.04480 , https://arxiv.org/abs/2510.26745 ) MLPs store geometric representations...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ChatGPT</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ChatGPT/comments/1r7v41w/chatgpt_gave_me_this_image/" target="_blank" rel="noopener">ChatGPT gave me this image.</a>
    </h3>

    
    <p class="card-summary">I typed in &amp;quot;Prompt: Based on our conversation history, create a picture of how you feel I treat you.&amp;quot; and ChatGPT gave me this image. Hahaha, it&#39;s so cute. &amp;#32; submitted by &amp;#32; /u/juseyeon [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/startups</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/startups/comments/1r7v248/musthave_hires_when_funding_is_tight_i_will_not/" target="_blank" rel="noopener">Must-have hires when funding is tight. I will not promote.</a>
    </h3>

    
    <p class="card-summary">How do you decide who to hire in a startup with pre-seed funding? I already have a backend engineer, and I handle product and design. How many hires do investors expect at this stage? What are the must-have hires? Also when is the best time to ask for seed funding? What I need to proof for that? &amp;#32; submitted by &amp;#32; /u/Wrong-Material-7435 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ethereum</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ethereum/comments/1r7v1qw/daily_general_discussion_february_18_2026/" target="_blank" rel="noopener">Daily General Discussion February 18, 2026</a>
    </h3>

    
    <p class="card-summary">Welcome to the Daily General Discussion on r/ethereum https://imgur.com/3y7vezP Bookmarking this link will always bring you to the current daily: https://old.reddit.com/r/ethereum/about/sticky/?num=2 Please use this thread to discuss Ethereum topics, news, events, and even price! Price discussion posted elsewhere in the subreddit will continue to be removed. As always, be constructive. -...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r7uyh9/running_your_own_llm_on_a_lan_accessible_by_a_dev/" target="_blank" rel="noopener">Running your own LLM on a LAN accessible by a dev team</a>
    </h3>

    
    <p class="card-summary">Let&#39;s say a team of 20 devs are cursor subscribers and they each consume 20-50$ usd per day in tokens by using a midrange Claude or GPT model. That adds up really quickly. Is it viable then to buy a large server, with let&#39;s say 4x RTX A6000 cards, for a total of 192 gb VRAM, running a pretty big model, and plenty of system ram? That would make it a pretty expensive server for sure, but certainly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">Decrypt</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://decrypt.co/358377/wall-street-prediction-markets-new-etf-filings" target="_blank" rel="noopener">Wall Street Pushes Deeper Into Prediction Markets With New ETF Filings</a>
    </h3>

    
    <p class="card-summary">Prediction market exposure is being packaged for public investors as the U.S. election cycle draws institutional interest.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/pumpfun-launches-cashback-coins-rewards?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Pump.fun rolls out trader cashbacks in tweak to memecoin model</a>
    </h3>

    
    <p class="card-summary">The rewards model follows months of criticism that too few Pump.fun traders were breaking even on the platform, let alone profiting.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/MachineLearning</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/MachineLearning/comments/1r7usv0/d_how_do_you_track_data_lineage_in_your_ml/" target="_blank" rel="noopener">[D] How do you track data lineage in your ML pipelines? Most teams I&#39;ve talked to do it manually (or not at all)</a>
    </h3>

    
    <p class="card-summary">I&#39;m a PhD student researching ML reproducibility, and one thing that keeps surprising me is how many teams have no systematic way to track which data went into which model. The typical workflow I see (and have been guilty of myself): Load some CSVs Clean and transform them through a chain of pandas operations Train a model Three months later, someone asks &amp;quot;what data was this model trained...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">Decrypt</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://decrypt.co/358374/oracle-error-leaves-defi-lender-moonwell-1-8-million-bad-debt" target="_blank" rel="noopener">Oracle Error Leaves DeFi Lender Moonwell With $1.8 Million in Bad Debt</a>
    </h3>

    
    <p class="card-summary">The error allowed liquidators to repay roughly $1 of debt to seize cbETH collateral, leaving Moonwell with nearly $1.8 million in bad debt.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ChatGPT</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ChatGPT/comments/1r7urf9/i_actually_hate_chatgpt_now/" target="_blank" rel="noopener">I actually hate ChatGPT now</a>
    </h3>

    
    <p class="card-summary">Why does ChatGPT needs to tell me to calm down or to take a pause in every prompt? Why all the gaslighting? I started with ChatGPT and absolutely loved it, and every month since I&#39;ve used it, it&#39;s gone worse. I don&#39;t really understand why. I&#39;m unsubscribing, what AIs do you suggest? Claude feels unusable right now, and Gemini doesn&#39;t convince me fully &amp;#32; submitted by &amp;#32...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r7upb5/personaplex7b_on_apple_silicon_mlx/" target="_blank" rel="noopener">PersonaPlex-7B on Apple Silicon (MLX)</a>
    </h3>

    
    <p class="card-summary">NVIDIA&#39;s open-source speech-to-speech model PersonaPlex-7B only includes a PyTorch + CUDA implementation targeting A100/H100, so I ported it to MLX, allowing it to run on Apple Silicon: github.com/mu-hashmi/personaplex-mlx. Hope you guys enjoy! &amp;#32; submitted by &amp;#32; /u/Apprehensive_Boot976 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/bitcoin-divergence-tech-fire-alarm-fiat-system-hayes?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Bitcoin’s tech stock divergence is a ‘fire alarm’ for fiat: Arthur Hayes</a>
    </h3>

    
    <p class="card-summary">Arthur Hayes warns that AI-related job losses will spark a credit crisis, forcing central banks to print money, which will drive Bitcoin to new all-time highs.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ChatGPT</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ChatGPT/comments/1r7uie2/okay_take_a_breath/" target="_blank" rel="noopener">Okay... Take a breath.</a>
    </h3>

    
    <p class="card-summary">I mean... I was just trying to visualise I cat that I had when I was a 3 y/o, didn&#39;t know the bot thinks I&#39;m having a panic attack lol &amp;#32; submitted by &amp;#32; /u/favouritebestie [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r7u50f/claude_vs_copilot_vs_codex/" target="_blank" rel="noopener">Claude vs Copilot vs Codex</a>
    </h3>

    
    <p class="card-summary">I got 2 - 7/10 difficulty bugs today, ideal for testing the new releases everywhere as per me. Context - The repository is a react app, every well structured, mono-repo combining 4 products (evolved over time). It&#39;s well setup for Claude and Copilot, not codex so I explicitly tell codex to read the instructions (we have them well documented for agents) Claude code - Enterprise (using Opus 4.6)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15034" target="_blank" rel="noopener">EduResearchBench: A Hierarchical Atomic Task Decomposition Benchmark for Full-Lifecycle Educational Research</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15034v1 Announce Type: new Abstract: While Large Language Models (LLMs) are reshaping the paradigm of AI for Social Science (AI4SS), rigorously evaluating their capabilities in scholarly writing remains a major challenge. Existing benchmarks largely emphasize single-shot, monolithic...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15038" target="_blank" rel="noopener">Indic-TunedLens: Interpreting Multilingual Models in Indian Languages</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15038v1 Announce Type: new Abstract: Multilingual large language models (LLMs) are increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain tailored to English. Prior work reveals that LLMs often operate in English centric representation...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15139" target="_blank" rel="noopener">CGRA-DeBERTa Concept Guided Residual Augmentation Transformer for Theologically Islamic Understanding</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15139v1 Announce Type: new Abstract: Accurate QA over classical Islamic texts remains challenging due to domain specific semantics, long context dependencies, and concept sensitive reasoning. Therefore, a new CGRA DeBERTa, a concept guided residual domain augmentation transformer...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15190" target="_blank" rel="noopener">AIC CTU@AVerImaTeC: dual-retriever RAG for image-text fact checking</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15190v1 Announce Type: new Abstract: In this paper, we present our 3rd place system in the AVerImaTeC shared task, which combines our last year&#39;s retrieval-augmented generation (RAG) pipeline with a reverse image search (RIS) module. Despite its simplicity, our system delivers...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15197" target="_blank" rel="noopener">OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15197v1 Announce Type: new Abstract: Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general &#34;search&#34; APIs) are often opaque, lacking clear best...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15312" target="_blank" rel="noopener">Extracting Consumer Insight from Text: A Large Language Model Approach to Emotion and Evaluation Measurement</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15312v1 Announce Type: new Abstract: Accurately measuring consumer emotions and evaluations from unstructured text remains a core challenge for marketing research and practice. This study introduces the Linguistic eXtractor (LX), a fine-tuned, large language model trained on...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15313" target="_blank" rel="noopener">Mnemis: Dual-Route Retrieval on Hierarchical Graphs for Long-Term LLM Memory</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15313v1 Announce Type: new Abstract: AI Memory, specifically how models organizes and retrieves historical messages, becomes increasingly valuable to Large Language Models (LLMs), yet existing methods (RAG and Graph-RAG) primarily retrieve memory through similarity-based mechanisms...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15353" target="_blank" rel="noopener">NeuroSymActive: Differentiable Neural-Symbolic Reasoning with Active Exploration for Knowledge Graph Question Answering</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15353v1 Announce Type: new Abstract: Large pretrained language models and neural reasoning systems have advanced many natural language tasks, yet they remain challenged by knowledge-intensive queries that require precise, structured multi-hop inference. Knowledge graphs provide a compact...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15373" target="_blank" rel="noopener">Far Out: Evaluating Language Models on Slang in Australian and Indian English</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15373v1 Announce Type: new Abstract: Language models exhibit systematic performance gaps when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang remains underexplored for several languages. We present a comprehensive evaluation of...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15377" target="_blank" rel="noopener">Orchestration-Free Customer Service Automation: A Privacy-Preserving and Flowchart-Guided Framework</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15377v1 Announce Type: new Abstract: Customer service automation has seen growing demand within digital transformation. Existing approaches either rely on modular system designs with extensive agent orchestration or employ over-simplified instruction schemas, providing limited guidance...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15378" target="_blank" rel="noopener">Making Large Language Models Speak Tulu: Structured Prompting for an Extremely Low-Resource Language</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15378v1 Announce Type: new Abstract: Can large language models converse in languages virtually absent from their training data? We investigate this question through a case study on Tulu, a Dravidian language with over 2 million speakers but minimal digital presence. Rather than...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15382" target="_blank" rel="noopener">The Vision Wormhole: Latent-Space Communication in Heterogeneous Multi-Agent Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15382v1 Announce Type: new Abstract: Multi-Agent Systems (MAS) powered by Large Language Models have unlocked advanced collaborative reasoning, yet they remain shackled by the inefficiency of discrete text communication, which imposes significant runtime overhead and information...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15436" target="_blank" rel="noopener">Measuring Social Integration Through Participation: Categorizing Organizations and Leisure Activities in the Displaced Karelians Interview Archive using LLMs</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15436v1 Announce Type: new Abstract: Digitized historical archives make it possible to study everyday social life on a large scale, but the information extracted directly from text often does not directly allow one to answer the research questions posed by historians or sociologists in a...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15449" target="_blank" rel="noopener">TAROT: Test-driven and Capability-adaptive Curriculum Reinforcement Fine-tuning for Code Generation with Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15449v1 Announce Type: new Abstract: Large Language Models (LLMs) are changing the coding paradigm, known as vibe coding, yet synthesizing algorithmically sophisticated and robust code still remains a critical challenge. Incentivizing the deep reasoning capabilities of LLMs is essential...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15456" target="_blank" rel="noopener">In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15456v1 Announce Type: new Abstract: Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms&#39; back-end databases or via web...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15504" target="_blank" rel="noopener">Towards Expectation Detection in Language: A Case Study on Treatment Expectations in Reddit</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15504v1 Announce Type: new Abstract: Patients&#39; expectations towards their treatment have a substantial effect on the treatments&#39; success. While primarily studied in clinical settings, online patient platforms like medical subreddits may hold complementary insights: treatment expectations...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15506" target="_blank" rel="noopener">LuxMT Technical Report</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15506v1 Announce Type: new Abstract: We introduce LuxMT, a machine translation system based on Gemma 3 27B and fine-tuned for translation from Luxembourgish (LB) into French (FR) and English (EN). To assess translation performance, we construct a novel benchmark covering LB-FR, LB-EN...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15509" target="_blank" rel="noopener">Fine-Refine: Iterative Fine-grained Refinement for Mitigating Dialogue Hallucination</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15509v1 Announce Type: new Abstract: The tendency for hallucination in current large language models (LLMs) negatively impacts dialogue systems. Such hallucinations produce factually incorrect responses that may mislead users and undermine system trust. Existing refinement methods for...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15514" target="_blank" rel="noopener">DependencyAI: Detecting AI Generated Text through Dependency Parsing</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15514v1 Announce Type: new Abstract: As large language models (LLMs) become increasingly prevalent, reliable methods for detecting AI-generated text are critical for mitigating potential risks. We introduce DependencyAI, a simple and interpretable approach for detecting AI-generated text...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15521" target="_blank" rel="noopener">ExpertWeaver: Unlocking the Inherent MoE in Dense LLMs with GLU Activation Patterns</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15521v1 Announce Type: new Abstract: Mixture-of-Experts (MoE) effectively scales model capacity while preserving computational efficiency through sparse expert activation. However, training high-quality MoEs from scratch is prohibitively expensive. A promising alternative is to convert...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15537" target="_blank" rel="noopener">ZeroSyl: Simple Zero-Resource Syllable Tokenization for Spoken Language Modeling</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15537v1 Announce Type: new Abstract: Pure speech language models aim to learn language directly from raw audio without textual resources. A key challenge is that discrete tokens from self-supervised speech encoders result in excessively long sequences, motivating recent work on...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15540" target="_blank" rel="noopener">Perspectives - Interactive Document Clustering in the Discourse Analysis Tool Suite</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15540v1 Announce Type: new Abstract: This paper introduces Perspectives, an interactive extension of the Discourse Analysis Tool Suite designed to empower Digital Humanities (DH) scholars to explore and organize large, unstructured document collections. Perspectives implements a...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15547" target="_blank" rel="noopener">jina-embeddings-v5-text: Task-Targeted Embedding Distillation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15547v1 Announce Type: new Abstract: Text embedding models are widely used for semantic similarity tasks, including information retrieval, clustering, and classification. General-purpose models are typically trained with single- or multi-stage processes using contrastive loss functions...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15564" target="_blank" rel="noopener">Beyond Static Pipelines: Learning Dynamic Workflows for Text-to-SQL</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15564v1 Announce Type: new Abstract: Text-to-SQL has recently achieved impressive progress, yet remains difficult to apply effectively in real-world scenarios. This gap stems from the reliance on single static workflows, fundamentally limiting scalability to out-of-distribution and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15578" target="_blank" rel="noopener">Clinically Inspired Symptom-Guided Depression Detection from Emotion-Aware Speech Representations</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15578v1 Announce Type: new Abstract: Depression manifests through a diverse set of symptoms such as sleep disturbance, loss of interest, and concentration difficulties. However, most existing works treat depression prediction either as a binary label or an overall severity score without...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15620" target="_blank" rel="noopener">STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15620v1 Announce Type: new Abstract: Reinforcement Learning (RL) has significantly improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic techniques such as entropy regularization and reweighting to maintain stability. In practice, they...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15675" target="_blank" rel="noopener">LLM-to-Speech: A Synthetic Data Pipeline for Training Dialectal Text-to-Speech Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15675v1 Announce Type: new Abstract: Despite the advances in neural text to speech (TTS), many Arabic dialectal varieties remain marginally addressed, with most resources concentrated on Modern Spoken Arabic (MSA) and Gulf dialects, leaving Egyptian Arabic -- the most widely understood...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15678" target="_blank" rel="noopener">Revisiting Northrop Frye&#39;s Four Myths Theory with Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15678v1 Announce Type: new Abstract: Northrop Frye&#39;s theory of four fundamental narrative genres (comedy, romance, tragedy, satire) has profoundly influenced literary criticism, yet computational approaches to his framework have focused primarily on narrative patterns rather than...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15689" target="_blank" rel="noopener">A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15689v1 Announce Type: new Abstract: Large language models and LLM-based agents are increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning academic policy frameworks and commercially deployed systems, often rely on broad...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15716" target="_blank" rel="noopener">Rethinking Metrics for Lexical Semantic Change Detection</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15716v1 Announce Type: new Abstract: Lexical semantic change detection (LSCD) increasingly relies on contextualised language model embeddings, yet most approaches still quantify change using a small set of semantic change metrics, primarily Average Pairwise Distance (APD) and cosine...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15730" target="_blank" rel="noopener">Causal Effect Estimation with Latent Textual Treatments</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15730v1 Announce Type: new Abstract: Understanding the causal effects of text on downstream outcomes is a central task in many applications. Estimating such effects requires researchers to run controlled experiments that systematically vary textual features. While large language models...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15753" target="_blank" rel="noopener">Under-resourced studies of under-resourced languages: lemmatization and POS-tagging with LLM annotators for historical Armenian, Georgian, Greek and Syriac</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15753v1 Announce Type: new Abstract: Low-resource languages pose persistent challenges for Natural Language Processing tasks such as lemmatization and part-of-speech (POS) tagging. This paper investigates the capacity of recent large language models (LLMs), including GPT-4 variants and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15757" target="_blank" rel="noopener">Beyond Binary Classification: Detecting Fine-Grained Sexism in Social Media Videos</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15757v1 Announce Type: new Abstract: Online sexism appears in various forms, which makes its detection challenging. Although automated tools can enhance the identification of sexist content, they are often restricted to binary classification. Consequently, more subtle manifestations of...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15758" target="_blank" rel="noopener">ChartEditBench: Evaluating Grounded Multi-Turn Chart Editing in Multimodal Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15758v1 Announce Type: new Abstract: While Multimodal Large Language Models (MLLMs) perform strongly on single-turn chart generation, their ability to support real-world exploratory data analysis remains underexplored. In practice, users iteratively refine visualizations through...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15769" target="_blank" rel="noopener">ViTaB-A: Evaluating Multimodal Large Language Models on Visual Table Attribution</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15769v1 Announce Type: new Abstract: Multimodal Large Language Models (mLLMs) are often used to answer questions in structured data such as tables in Markdown, JSON, and images. While these models can often give correct answers, users also need to know where those answers come from. In...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15778" target="_blank" rel="noopener">*-PLUIE: Personalisable metric with Llm Used for Improved Evaluation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15778v1 Announce Type: new Abstract: Evaluating the quality of automatically generated text often relies on LLM-as-a-judge (LLM-judge) methods. While effective, these approaches are computationally expensive and require post-processing. To address these limitations, we build upon...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15814" target="_blank" rel="noopener">Avey-B</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15814v1 Announce Type: new Abstract: Compact pretrained bidirectional encoders remain the backbone of industrial NLP under tight compute and memory budgets. Their effectiveness stems from self-attention&#39;s ability to deliver high-quality bidirectional contextualization with sequence-level...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15143" target="_blank" rel="noopener">Protecting Language Models Against Unauthorized Distillation through Trace Rewriting</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15143v1 Announce Type: cross Abstract: Knowledge distillation is a widely adopted technique for transferring capabilities from LLMs to smaller, more efficient student models. However, unauthorized use of knowledge distillation takes unfair advantage of the considerable effort and cost...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15183" target="_blank" rel="noopener">Seeing to Generalize: How Visual Data Corrects Binding Shortcuts</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15183v1 Announce Type: cross Abstract: Vision Language Models (VLMs) are designed to extend Large Language Models (LLMs) with visual capabilities, yet in this work we observe a surprising phenomenon: VLMs can outperform their underlying LLMs on purely text-only tasks, particularly in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15189" target="_blank" rel="noopener">ScrapeGraphAI-100k: A Large-Scale Dataset for LLM-Based Web Information Extraction</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15189v1 Announce Type: cross Abstract: The use of large language models for web information extraction is becoming increasingly fundamental to modern web information retrieval pipelines. However, existing datasets tend to be small, synthetic or text-only, failing to capture the...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15195" target="_blank" rel="noopener">Weight space Detection of Backdoors in LoRA Adapters</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15195v1 Announce Type: cross Abstract: LoRA adapters let users fine-tune large language models (LLMs) efficiently. However, LoRA adapters are shared through open repositories like Hugging Face Hub \citep{huggingface_hub_docs}, making them vulnerable to backdoor attacks. Current detection...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15198" target="_blank" rel="noopener">Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15198v1 Announce Type: cross Abstract: Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \emph{collude}...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15257" target="_blank" rel="noopener">How to Train Your Long-Context Visual Document Model</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15257v1 Announce Type: cross Abstract: We present the first comprehensive, large-scale study of training long-context vision language models up to 344K context, targeting long-document visual question answering with measured transfer to long-context text. While several such strong are...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15273" target="_blank" rel="noopener">FrameRef: A Framing Dataset and Simulation Testbed for Modeling Bounded Rational Information Health</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15273v1 Announce Type: cross Abstract: Information ecosystems increasingly shape how people internalize exposure to adverse digital experiences, raising concerns about the long-term consequences for information health. In modern search and recommendation systems, ranking and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15293" target="_blank" rel="noopener">The Information Geometry of Softmax: Probing and Steering</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15293v1 Announce Type: cross Abstract: This paper concerns the question of how AI systems encode semantic structure into the geometric structure of their representation spaces. The motivating observation of this paper is that the natural geometry of these representation spaces should...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15327" target="_blank" rel="noopener">Prescriptive Scaling Reveals the Evolution of Language Model Capabilities</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15327v1 Announce Type: cross Abstract: For deploying foundation models, practitioners increasingly need prescriptive scaling laws: given a pre training compute budget, what downstream accuracy is attainable with contemporary post training practice, and how stable is that mapping as the...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15338" target="_blank" rel="noopener">Discovering Implicit Large Language Model Alignment Objectives</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15338v1 Announce Type: cross Abstract: Large language model (LLM) alignment relies on complex reward signals that often obscure the specific behaviors being incentivized, creating critical risks of misalignment and reward hacking. Existing interpretation methods typically rely on...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15384" target="_blank" rel="noopener">World-Model-Augmented Web Agents with Action Correction</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15384v1 Announce Type: cross Abstract: Web agents based on large language models have demonstrated promising capability in automating web tasks. However, current web agents struggle to reason out sensible actions due to the limitations of predicting environment changes, and might not...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15553" target="_blank" rel="noopener">RUVA: Personalized Transparent On-Device Graph Reasoning</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15553v1 Announce Type: cross Abstract: The Personal AI landscape is currently dominated by &#34;Black Box&#34; Retrieval-Augmented Generation. While standard vector databases offer statistical matching, they suffer from a fundamental lack of accountability: when an AI hallucinates or retrieves...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15707" target="_blank" rel="noopener">Proactive Conversational Assistant for a Procedural Manual Task based on Audio and IMU</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15707v1 Announce Type: cross Abstract: Real-time conversational assistants for procedural tasks often depend on video input, which can be computationally expensive and compromise user privacy. For the first time, we propose a real-time conversational assistant that provides comprehensive...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15725" target="_blank" rel="noopener">Recursive Concept Evolution for Compositional Reasoning in Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15725v1 Announce Type: cross Abstract: Large language models achieve strong performance on many complex reasoning tasks, yet their accuracy degrades sharply on benchmarks that require compositional reasoning, including ARC-AGI-2, GPQA, MATH, BBH, and HLE. Existing methods improve...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15763" target="_blank" rel="noopener">GLM-5: from Vibe Coding to Agentic Engineering</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15763v1 Announce Type: cross Abstract: We present GLM-5, a next-generation foundation model designed to transition the paradigm of vibe coding to agentic engineering. Building upon the agentic, reasoning, and coding (ARC) capabilities of its predecessor, GLM-5 adopts DSA to significantly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15791" target="_blank" rel="noopener">Enhancing Building Semantics Preservation in AI Model Training with Large Language Model Encodings</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15791v1 Announce Type: cross Abstract: Accurate representation of building semantics, encompassing both generic object types and specific subtypes, is essential for effective AI model training in the architecture, engineering, construction, and operation (AECO) industry. Conventional...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2407.03646" target="_blank" rel="noopener">Differentiating Between Human-Written and AI-Generated Texts Using Automatically Extracted Linguistic Features</a>
    </h3>

    
    <p class="card-summary">arXiv:2407.03646v4 Announce Type: replace Abstract: While extensive research has focused on ChatGPT in recent years, very few studies have systematically quantified and compared linguistic features between human-written and artificial intelligence (AI)-generated language. This exploratory study...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2408.00539" target="_blank" rel="noopener">Intermittent Semi-Working Mask: A New Masking Paradigm for LLMs</a>
    </h3>

    
    <p class="card-summary">arXiv:2408.00539v2 Announce Type: replace Abstract: Multi-turn dialogues and context-intensive tasks challenge Large Language Models (LLMs) to integrate long histories without sacrificing generation quality. Although prefix LLMs can better exploit historical context via bidirectional attention on...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2409.11733" target="_blank" rel="noopener">Human-like Affective Cognition in Foundation Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2409.11733v3 Announce Type: replace Abstract: Understanding emotions is fundamental to human interaction and experience. Humans easily infer emotions from situations or facial expressions, situations from emotions, and do a variety of other affective cognition. How adept is modern AI at these...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2502.16051" target="_blank" rel="noopener">Moving Beyond Medical Exams: A Clinician-Annotated Fairness Dataset of Real-World Tasks and Ambiguity in Mental Healthcare</a>
    </h3>

    
    <p class="card-summary">arXiv:2502.16051v3 Announce Type: replace Abstract: Current medical language model (LM) benchmarks often over-simplify the complexities of day-to-day clinical practice tasks and instead rely on evaluating LMs on multiple-choice board exam questions. In psychiatry especially, these challenges are...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2502.17812" target="_blank" rel="noopener">Can Multimodal LLMs Perform Time Series Anomaly Detection?</a>
    </h3>

    
    <p class="card-summary">arXiv:2502.17812v2 Announce Type: replace Abstract: Time series anomaly detection (TSAD) has been a long-standing pillar problem in Web-scale systems and online infrastructures, such as service reliability monitoring, system fault diagnosis, and performance optimization. Large language models...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2502.19412" target="_blank" rel="noopener">The Mighty ToRR: A Benchmark for Table Reasoning and Robustness</a>
    </h3>

    
    <p class="card-summary">arXiv:2502.19412v3 Announce Type: replace Abstract: Despite its real-world significance, model performance on tabular data remains underexplored, leaving uncertainty about which model to rely on and which prompt configuration to adopt. To address this gap, we create ToRR, a benchmark for Table...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2503.17900" target="_blank" rel="noopener">MedPlan: A Two-Stage RAG-Based System for Personalized Medical Plan Generation</a>
    </h3>

    
    <p class="card-summary">arXiv:2503.17900v3 Announce Type: replace Abstract: Despite recent success in applying large language models (LLMs) to electronic health records (EHR), most systems focus primarily on assessment rather than treatment planning. We identify three critical limitations in current approaches: they...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2504.06438" target="_blank" rel="noopener">Don&#39;t Let It Hallucinate: Premise Verification via Retrieval-Augmented Logical Reasoning</a>
    </h3>

    
    <p class="card-summary">arXiv:2504.06438v2 Announce Type: replace Abstract: Large language models (LLMs) have shown substantial capacity for generating fluent, contextually appropriate responses. However, they can produce hallucinated outputs, especially when a user query includes one or more false premises-claims that...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2505.13147" target="_blank" rel="noopener">What if Deception Cannot be Detected? A Cross-Linguistic Study on the Limits of Deception Detection from Text</a>
    </h3>

    
    <p class="card-summary">arXiv:2505.13147v3 Announce Type: replace Abstract: Can deception be detected solely from written text? Cues of deceptive communication are inherently subtle, even more so in text-only communication. Yet, prior studies have reported considerable success in automatic deception detection. We...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.16594" target="_blank" rel="noopener">A Scoping Review of Synthetic Data Generation by Language Models in Biomedical Research and Application: Data Utility and Quality Perspectives</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.16594v2 Announce Type: replace Abstract: Synthetic data generation using large language models (LLMs) demonstrates substantial promise in addressing biomedical data challenges and shows increasing adoption in biomedical research. This study systematically reviews recent advances in...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.19919" target="_blank" rel="noopener">Your AI Bosses Are Still Prejudiced: The Emergence of Stereotypes in LLM-Based Multi-Agent Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.19919v2 Announce Type: replace Abstract: While stereotypes are well-documented in human social interactions, AI systems are often presumed to be less susceptible to such biases. Previous studies have focused on biases inherited from training data, but whether stereotypes can emerge...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.20373" target="_blank" rel="noopener">NPG-Muse: Scaling Long Chain-of-Thought Reasoning with NP-Hard Graph Problems</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.20373v2 Announce Type: replace Abstract: Reasoning Large Language Models (RLLMs) have recently achieved remarkable progress on complex reasoning tasks, largely enabled by their long chain-of-thought (Long CoT) capabilities. However, developing these Long CoT behaviors relies heavily on...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2509.22211" target="_blank" rel="noopener">LogiPart: Local Large Language Models for Data Exploration at Scale with Logical Partitioning</a>
    </h3>

    
    <p class="card-summary">arXiv:2509.22211v3 Announce Type: replace Abstract: The discovery of deep, steerable taxonomies in large text corpora is currently restricted by a trade-off between the surface-level efficiency of topic models and the prohibitive, non-scalable assignment costs of LLM-integrated frameworks. We...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.02348" target="_blank" rel="noopener">mini-vec2vec: Scaling Universal Geometry Alignment with Linear Transformations</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.02348v4 Announce Type: replace Abstract: We build upon vec2vec, a procedure designed to align text embedding spaces without parallel data. vec2vec finds a near-perfect alignment, but it is expensive and unstable. We present mini-vec2vec, a simple and efficient alternative that requires...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.10902" target="_blank" rel="noopener">Multimodal Peer Review Simulation with Actionable To-Do Recommendations for Community-Aware Manuscript Revisions</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.10902v2 Announce Type: replace Abstract: While large language models (LLMs) offer promising capabilities for automating academic workflows, existing systems for academic peer review remain constrained by text-only inputs, limited contextual grounding, and a lack of actionable feedback...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2512.19117" target="_blank" rel="noopener">Stop saying LLM: Large Discourse Models (LDM) and Artificial Discursive Agent (ADA)?</a>
    </h3>

    
    <p class="card-summary">arXiv:2512.19117v2 Announce Type: replace Abstract: This paper proposes an epistemological shift in the analysis of large generative models, replacing the category &#39;&#39;Large Language Models&#39;&#39; (LLM) with that of &#39;&#39;Large Discourse Models&#39;&#39; (LDM), and then with that of Artificial Discursive Agent (ADA)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.11932" target="_blank" rel="noopener">Event Detection with a Context-Aware Encoder and LoRA for Improved Performance on Long-Tailed Classes</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.11932v2 Announce Type: replace Abstract: The current state of event detection research has two notable re-occurring limitations that we investigate in this study. First, the unidirectional nature of decoder-only LLMs presents a fundamental architectural bottleneck for natural language...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.15298" target="_blank" rel="noopener">Embedding Retrofitting: Data Engineering for better RAG</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.15298v2 Announce Type: replace Abstract: Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.02108" target="_blank" rel="noopener">Out of the Memory Barrier: A Highly Memory Efficient Training System for LLMs with Million-Token Contexts</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.02108v3 Announce Type: replace Abstract: Training Large Language Models (LLMs) on long contexts is severely constrained by prohibitive GPU memory overhead, not training time. The primary culprits are the activations, whose memory footprints scale linearly with sequence length. We...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.07812" target="_blank" rel="noopener">LLMs Know More About Numbers than They Can Say</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.07812v2 Announce Type: replace Abstract: Although state-of-the-art LLMs can solve math problems, we find that they make errors on numerical comparisons with mixed notation: &#34;Which is larger, $5.7 \times 10^2$ or $580$?&#34; This raises a fundamental question: Do LLMs even know how big these...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2406.07990" target="_blank" rel="noopener">Topological quantification of ambiguity in semantic search</a>
    </h3>

    
    <p class="card-summary">arXiv:2406.07990v2 Announce Type: replace-cross Abstract: We studied how the local topological structure of sentence-embedding neighborhoods encodes semantic ambiguity. Extending ideas that link word-level polysemy to non-trivial persistent homology, we generalized the concept to full sentences and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2411.12174" target="_blank" rel="noopener">Just KIDDIN: Knowledge Infusion and Distillation for Detection of INdecent Memes</a>
    </h3>

    
    <p class="card-summary">arXiv:2411.12174v3 Announce Type: replace-cross Abstract: Toxicity identification in online multimodal environments remains a challenging task due to the complexity of contextual connections across modalities (e.g., textual and visual). In this paper, we propose a novel framework that integrates...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2502.00225" target="_blank" rel="noopener">Should You Use Your Large Language Model to Explore or Exploit?</a>
    </h3>

    
    <p class="card-summary">arXiv:2502.00225v3 Announce Type: replace-cross Abstract: We evaluate the ability of the current generation of large language models (LLMs) to help a decision-making agent facing an exploration-exploitation tradeoff. While previous work has largely study the ability of LLMs to solve combined...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2502.18545" target="_blank" rel="noopener">PII-Bench: Evaluating Query-Aware Privacy Protection Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2502.18545v2 Announce Type: replace-cross Abstract: The widespread adoption of Large Language Models (LLMs) has raised significant privacy concerns regarding the exposure of personally identifiable information (PII) in user prompts. To address this challenge, we propose a query-unrelated PII...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2505.05736" target="_blank" rel="noopener">Multimodal Integrated Knowledge Transfer to Large Language Models through Preference Optimization with Biomedical Applications</a>
    </h3>

    
    <p class="card-summary">arXiv:2505.05736v2 Announce Type: replace-cross Abstract: The scarcity of high-quality multimodal biomedical data limits the ability to effectively fine-tune pretrained Large Language Models (LLMs) for specialized biomedical tasks. To address this challenge, we introduce MINT (Multimodal Integrated...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.03269" target="_blank" rel="noopener">General Exploratory Bonus for Optimistic Exploration in RLHF</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.03269v4 Announce Type: replace-cross Abstract: Optimistic exploration is central to improving sample efficiency in reinforcement learning with human feedback, yet existing exploratory bonus methods to incentivize exploration often fail to realize optimism. We provide a theoretical...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.05705" target="_blank" rel="noopener">Long Grounded Thoughts: Synthesizing Visual Problems and Reasoning Chains at Scale</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.05705v2 Announce Type: replace-cross Abstract: Despite rapid progress, multimodal reasoning still lacks a systematic approach to synthesize large-scale vision-centric datasets beyond visual math. We introduce a framework able to synthesize vision-centric problems spanning diverse levels...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.07587" target="_blank" rel="noopener">Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.07587v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.11104" target="_blank" rel="noopener">CLARITY: Contextual Linguistic Adaptation and Accent Retrieval for Dual-Bias Mitigation in Text-to-Speech Generation</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.11104v2 Announce Type: replace-cross Abstract: Instruction-guided text-to-speech (TTS) research has reached a maturity level where excellent speech generation quality is possible on demand, yet two coupled biases persist in reducing perceived quality: accent bias, where models default...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.15719" target="_blank" rel="noopener">Chain of Summaries: Summarization Through Iterative Questioning</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.15719v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) are increasingly using external web content. However, much of this content is not easily digestible by LLMs due to LLM-unfriendly formats and limitations of context length. To address this issue, we propose a...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2512.03262" target="_blank" rel="noopener">Is Vibe Coding Safe? Benchmarking Vulnerability of Agent-Generated Code in Real-World Tasks</a>
    </h3>

    
    <p class="card-summary">arXiv:2512.03262v2 Announce Type: replace-cross Abstract: Vibe coding is a new programming paradigm in which human engineers instruct large language model (LLM) agents to complete complex coding tasks with little supervision. Although vibe coding is increasingly adopted, are its outputs really safe...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.01297" target="_blank" rel="noopener">ARGUS: Adaptive Rotation-Invariant Geometric Unsupervised System</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.01297v2 Announce Type: replace-cross Abstract: Detecting distributional drift in high-dimensional data streams presents fundamental challenges: global comparison methods scale poorly, projection-based approaches lose geometric structure, and re-clustering methods suffer from identity...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.02799" target="_blank" rel="noopener">Stratified Hazard Sampling: Minimal-Variance Event Scheduling for CTMC/DTMC Discrete Diffusion and Flow Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.02799v2 Announce Type: replace-cross Abstract: Uniform-noise discrete diffusion and flow models (e.g., D3PM, SEDD, UDLM, DFM) generate sequences non-autoregressively by iteratively refining randomly initialized vocabulary tokens through multiple context-dependent replacements. These...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.15812" target="_blank" rel="noopener">ErrorMap and ErrorAtlas: Charting the Failure Landscape of Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.15812v2 Announce Type: replace-cross Abstract: Large Language Models (LLM) benchmarks tell us when models fail, but not why they fail. A wrong answer on a reasoning dataset may stem from formatting issues, calculation errors, or dataset noise rather than weak reasoning. Without...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Machine Learning</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15076" target="_blank" rel="noopener">Near-Optimal Sample Complexity for Online Constrained MDPs</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15076v1 Announce Type: new Abstract: Safety is a fundamental challenge in reinforcement learning (RL), particularly in real-world applications such as autonomous driving, robotics, and healthcare. To address this, Constrained Markov Decision Processes (CMDPs) are commonly used to enforce...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Machine Learning</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">2h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.15089" target="_blank" rel="noopener">Hybrid Feature Learning with Time Series Embeddings for Equipment Anomaly Prediction</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.15089v1 Announce Type: new Abstract: In predictive maintenance of equipment, deep learning-based time series anomaly detection has garnered significant attention; however, pure deep learning approaches often fail to achieve sufficient accuracy on real-world data. This study proposes a...</p>
    

    
</article>
    
</div>


    </main>

    <footer class="site-footer">
        <div class="container">
            <p>Last updated: February 18, 2026 at 07:35 UTC</p>
            <p>445 articles from 22 sources</p>
            <p>Daily Signal Feed &mdash; AI, Web3 &amp; Emerging Tech Aggregator</p>
        </div>
    </footer>

    <script>
    // Client-side search filter
    document.addEventListener('DOMContentLoaded', function() {
        const searchBar = document.querySelector('.search-bar');
        if (searchBar) {
            searchBar.addEventListener('input', function(e) {
                const query = e.target.value.toLowerCase();
                const cards = document.querySelectorAll('.article-card, .archive-item');
                cards.forEach(function(card) {
                    const text = card.textContent.toLowerCase();
                    card.style.display = text.includes(query) ? '' : 'none';
                });
            });
        }
    });
    </script>
</body>
</html>