<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Daily Signal Feed — AI, Web3 & Emerging Trends</title>
    <link rel="stylesheet" href="/daily-signal-feed/css/style.css">
    <meta name="description" content="AI, Web3, and emerging tech news aggregated from 50+ sources with trend detection.">
</head>
<body>
    <header class="site-header">
        <div class="container header-inner">
            <a href="/daily-signal-feed/" class="site-logo">
                <h1>Daily Signal Feed</h1>
                <span class="tagline">AI &bull; Web3 &bull; Emerging Trends</span>
            </a>
            <nav class="main-nav">
                <a href="/daily-signal-feed/" class="active">Home</a>
                
                <a href="/daily-signal-feed/category/ai-llms.html"
                   class="">
                    AI &amp; LLMs (418)
                </a>
                
                <a href="/daily-signal-feed/category/web3-defi.html"
                   class="">
                    Web3 &amp; DeFi (15)
                </a>
                
                <a href="/daily-signal-feed/category/deals.html"
                   class="">
                    Deals &amp; Acquisitions (4)
                </a>
                
                <a href="/daily-signal-feed/category/new-tools.html"
                   class="">
                    New Tools &amp; Apps (6)
                </a>
                
                <a href="/daily-signal-feed/category/regulation.html"
                   class="">
                    Regulation &amp; Policy
                </a>
                
                <a href="/daily-signal-feed/category/social-buzz.html"
                   class="">
                    Social Buzz (45)
                </a>
                
                <a href="/daily-signal-feed/category/emerging-trends.html"
                   class="">
                    Emerging Trends
                </a>
                
                <a href="/daily-signal-feed/archive.html" class="">Archive</a>
            </nav>
        </div>
    </header>

    <main class="container">
        
<!-- Executive Summary -->
<section class="exec-summary">
    <h2>Signal Summary</h2>

    <div class="summary-grid">
        <!-- Trending Topics -->
        <div class="summary-card">
            <h3>Trending Now</h3>
            <ul class="trend-list">
                
                <li class="trend-item">
                    <span class="trend-term">Open</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">GitHub</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">4 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Large Language Model</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">7 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Mind</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">5 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Safety</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">4 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">MARL</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">17 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
                <li class="trend-item">
                    <span class="trend-term">Modern</span>
                    <span class="trend-meta">
                        <span class="trend-mentions">8 mentions</span>
                        <span class="trend-direction up">
                            &uarr;
                        </span>
                    </span>
                </li>
                
            </ul>
        </div>

        <!-- Category Activity -->
        <div class="summary-card">
            <h3>Category Activity</h3>
            <div class="cat-bars">
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">AI &amp; LLMs</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 100%; background: #4F46E5;"></div>
                    </div>
                    <span class="cat-bar-count">418</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Social Buzz</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 11%; background: #06B6D4;"></div>
                    </div>
                    <span class="cat-bar-count">45</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Web3 &amp; DeFi</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 4%; background: #8B5CF6;"></div>
                    </div>
                    <span class="cat-bar-count">15</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">New Tools &amp; Apps</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 1%; background: #F59E0B;"></div>
                    </div>
                    <span class="cat-bar-count">6</span>
                </div>
                
                
                
                <div class="cat-bar">
                    <span class="cat-bar-label">Deals &amp; Acquisitions</span>
                    <div class="cat-bar-track">
                        <div class="cat-bar-fill" style="width: 1%; background: #EC4899;"></div>
                    </div>
                    <span class="cat-bar-count">4</span>
                </div>
                
                
                
                
                
                
            </div>
        </div>

        <!-- Stats -->
        <div class="summary-card">
            <h3>Today's Signal</h3>
            <div class="stat-grid">
                <div class="stat-item">
                    <div class="stat-value">488</div>
                    <div class="stat-label">Articles</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">20</div>
                    <div class="stat-label">Sources</div>
                </div>
                <div class="stat-item">
                    <div class="stat-value">27</div>
                    <div class="stat-label">Trending</div>
                </div>
                <div class="stat-item">
                    <span class="momentum-badge momentum-accelerating">
                        accelerating
                    </span>
                    <div class="stat-label">Momentum</div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Search -->
<input type="text" class="search-bar" placeholder="Search articles by title, source, or keyword..." aria-label="Search articles">

<!-- Trending Articles -->

<section>
    <div class="section-header">
        <h2>Trending Now</h2>
    </div>
    <div class="article-grid">
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/MachineLearning</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/MachineLearning/comments/1r9mbtc/p_open_source_llm_gateway_in_rust_looking_for/" target="_blank" rel="noopener">[P] Open source LLM gateway in Rust looking for feedback and contributors</a>
    </h3>

    
    <p class="card-summary">Hey everyone, We have been working on a project called Sentinel. It is a fast LLM gateway written in Rust that gives you a single OpenAI compatible endpoint while routing to multiple providers under the hood. The idea came from dealing with multiple LLM APIs in production and getting tired of managing retries, failover logic, cost tracking, caching, and privacy concerns in every app. We wanted...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17542" target="_blank" rel="noopener">Using LLMs for Knowledge Component-level Correctness Labeling in Open-ended Coding Problems</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17542v1 Announce Type: new Abstract: Fine-grained skill representations, commonly referred to as knowledge components (KCs), are fundamental to many approaches in student modeling and learning analytics. However, KC-level correctness labels are rarely available in real-world datasets...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16819" target="_blank" rel="noopener">Hybrid-Gym: Training Coding Agents to Generalize Across Tasks</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16819v1 Announce Type: cross Abstract: When assessing the quality of coding agents, predominant benchmarks focus on solving single issues on GitHub, such as SWE-Bench. In contrast, in real use, these agents solve more various and complex tasks that involve other skills such as exploring...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Machine Learning</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17314" target="_blank" rel="noopener">Open Datasets in Learning Analytics: Trends, Challenges, and Best PRACTICE</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17314v1 Announce Type: cross Abstract: Open datasets play a crucial role in three research domains that intersect data science and education: learning analytics, educational data mining, and artificial intelligence in education. Researchers in these domains apply computational methods to...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Machine Learning</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2410.13957" target="_blank" rel="noopener">Goal Inference from Open-Ended Dialog</a>
    </h3>

    
    <p class="card-summary">arXiv:2410.13957v2 Announce Type: replace-cross Abstract: Embodied AI Agents are quickly becoming important and common tools in society. These embodied agents should be able to learn about and accomplish a wide range of user goals and preferences efficiently and robustly. Large Language Models...</p>
    

    
</article>
        
            <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Artificial Intelligence</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17084" target="_blank" rel="noopener">How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17084v1 Announce Type: new Abstract: The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers...</p>
    

    
</article>
        
    </div>
</section>


<!-- Latest by Date -->

<h3 class="date-label">February 20, 2026</h3>
<div class="article-grid">
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">8m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r9nycn/best_way_to_train_bodyonly_lora_in_onetrainer/" target="_blank" rel="noopener">Best way to train body-only LoRA in OneTrainer without learning the face</a>
    </h3>

    
    <p class="card-summary">I&#39;m trying to train a body LoRA (body shape, clothing, pose) in OneTrainer while completely excluding the face from learning. Here are the methods I&#39;ve tried so far and the results: Painting the face area pure white (255) directly on the original images → Face learning is almost completely prevented, but during generation, white patches/circles frequently appear on the face area (It&#39;s usable, but...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">22m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r9np6k/what_gpu_would_be_good_to_learn_on/" target="_blank" rel="noopener">What GPU would be good to learn on?</a>
    </h3>

    
    <p class="card-summary">Howdy y&#39;all, Recently came into some good luck and got a dell r730 for free. It has, 128gb ddr4 2670v3 80~tb of ssd storage What GPU would be worthwhile to put into this thing? I&#39;m not the most tech savvy person but the P40 at first seemed like some promising bang for buck but the more I read it doesn&#39;t seem worthwhile. That leads me to the V100 32gb being a touch more recent but it seems that...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">TechCrunch - Venture</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">24m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://techcrunch.com/2026/02/19/ali-partovis-neo-looks-to-upend-the-accelerator-model-with-low-dilution-terms/" target="_blank" rel="noopener">Ali Partovi’s Neo looks to upend the accelerator model with low-dilution terms</a>
    </h3>

    
    <p class="card-summary">Neo&#39;s new Residency program invests $750,000 in an uncapped SAFE for startups and provides a $40,000 no-strings-attached grant for college students.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">27m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/20/bitcoin-nears-usd68-000-gold-jumps-as-us-iran-tensions-return" target="_blank" rel="noopener">Bitcoin nears $68,000, gold jumps as US-Iran tensions return</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">33m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/parsec-defi-nft-analytics-platform-closes-market-volatility?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">Parsec shuts down amid ongoing crypto market volatility</a>
    </h3>

    
    <p class="card-summary">The on-chain analytics firm‘s focus on decentralized finance and non-fungible tokens had fallen out of step with the industry‘s current trajectory.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/StableDiffusion</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">36m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/StableDiffusion/comments/1r9ng79/windows_stuttering_after_generations/" target="_blank" rel="noopener">Windows stuttering after generations</a>
    </h3>

    
    <p class="card-summary">Hi! Just as the title. It happens with: Qwen Wan Zit (less dramatic, but it does). Haven&#39;t tried other models, but I believe it will happen as well. Everything was working fine till yesterday. Already tried a fresh confyui installation. I&#39;m using Easy install 32gb ddr4 5060ti 16 gb (new card, less than 1 month old) I have tried with and without pagefile virtual ram Temps are fine I run clean vram...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/ethereum</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">37m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ethereum/comments/1r9nfzz/daily_general_discussion_february_20_2026/" target="_blank" rel="noopener">Daily General Discussion February 20, 2026</a>
    </h3>

    
    <p class="card-summary">Welcome to the Daily General Discussion on r/ethereum https://imgur.com/3y7vezP Bookmarking this link will always bring you to the current daily: https://old.reddit.com/r/ethereum/about/sticky/?num=2 Please use this thread to discuss Ethereum topics, news, events, and even price! Price discussion posted elsewhere in the subreddit will continue to be removed. As always, be constructive. -...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/startups</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">37m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/startups/comments/1r9nfuc/feedback_friday/" target="_blank" rel="noopener">Feedback Friday</a>
    </h3>

    
    <p class="card-summary">Welcome to this week’s Feedback Thread! Please use this thread appropriately to gather feedback: Feel free to request general feedback or specific feedback in a certain area like user experience, usability, design, landing page(s), or code review You may share surveys You may make an additional request for beta testers Promo codes and affiliates links are ONLY allowed if they are for your product...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/startups</span>
        <span class="card-category" style="background: #EC4899;">
            Deals &amp; Acquisitions
        </span>
        <span class="card-time">41m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/startups/comments/1r9nd7m/evaluating_a_startup_offer_i_will_not_promote/" target="_blank" rel="noopener">Evaluating a Startup Offer I will not promote</a>
    </h3>

    
    <p class="card-summary">Hi everyone I’m not too familiar with the startup scene so was hoping for some perspectives to evaluate a recent job offer I received from a tech startup ~$15mil ARR growing fast and yet to raise. Will avoid saying more for confidentially reasons. The role is for Head of Strategy and offer is 210k base and 1% equity. On the converse I have an offer from a prominent consulting firm for (~$350k)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">50m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/20/bitcoin-logs-worst-ever-start-to-a-year-through-first-50-days" target="_blank" rel="noopener">Bitcoin logs worst first 50-day start to a year on record</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">59m ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r9n19a/i_tried_fixing_ais_inconsistency_problem_by/" target="_blank" rel="noopener">I tried fixing AI’s inconsistency problem by building this</a>
    </h3>

    
    <p class="card-summary">I use OpenAI models daily for writing and structuring ideas. What I kept noticing was not a lack of intelligence, but a lack of stability. I would define a clear tone and structure at the start of a session, and it would follow it well. A few prompts later, the style would slowly drift. The content was still good, but the formatting and voice would change. It is not really a context window issue...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r9mzvr/hmm_i_wonder_why_they_removed_4o/" target="_blank" rel="noopener">Hmm, I wonder why they removed 4o?</a>
    </h3>

    
    <p class="card-summary">Absolute insanity over at r/ChatGPTcomplaints If you can’t understand why OpenAI wanted to distance themselves from this type of user you must be as insane as Jane’s baby daddy. &amp;#32; submitted by &amp;#32; /u/RealMelonBread [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/OpenAI</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/OpenAI/comments/1r9mytj/codexwebui_browser_ui_for_local_codex_desktopcli/" target="_blank" rel="noopener">codex-web-ui: browser UI for local Codex (Desktop/CLI backend)</a>
    </h3>

    
    <p class="card-summary">Quick setup for WebUI mode npx codex-web-ui --port 5999 If you&#39;ve ever wished you could use the Codex Desktop interface from your phone, tablet, another computer, or even while traveling without being stuck on your Mac good news: it&#39;s now possible thanks to https://github.com/friuns2/codex-unpacked-toolkit The idea is simple: run Codex locally, access it from the browser, and optionally expose it...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ChatGPT</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ChatGPT/comments/1r9mv08/bro_chill_wtff/" target="_blank" rel="noopener">Bro chill wtff</a>
    </h3>

    
    <p class="card-summary">&amp;#32; submitted by &amp;#32; /u/DataOk1825 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinDesk</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.coindesk.com/markets/2026/02/20/metaplanet-ceo-rebuts-critics-over-bitcoin-strategy-and-transparency" target="_blank" rel="noopener">Metaplanet CEO rebuts critics over bitcoin strategy and transparency</a>
    </h3>

    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/ethereum</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/ethereum/comments/1r9msb7/how_much_do_you_know_about_ethereum/" target="_blank" rel="noopener">How much do you know about Ethereum ?</a>
    </h3>

    
    <p class="card-summary">&amp;#32; submitted by &amp;#32; /u/Rum3ths [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/cryptocurrency</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/CryptoCurrency/comments/1r9mr9k/bitmine_buys_record_45759_eth/" target="_blank" rel="noopener">BitMine Buys Record 45,759 ETH</a>
    </h3>

    
    <p class="card-summary">&amp;#32; submitted by &amp;#32; /u/diwalost [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">CoinTelegraph</span>
        <span class="card-category" style="background: #8B5CF6;">
            Web3 &amp; DeFi
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://cointelegraph.com/news/crypto-banks-meet-white-house-stablecoin-rewards?utm_source=rss_feed&amp;utm_medium=rss&amp;utm_campaign=rss_partner_inbound" target="_blank" rel="noopener">White House floats limited stablecoin rewards in 3rd crypto, bank meeting</a>
    </h3>

    
    <p class="card-summary">White House crypto adviser Patrick Witt reportedly refocused crypto and bank lobby talks on a crypto bill to allow stablecoin rewards tied to transaction activity.</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/SideProject</span>
        <span class="card-category" style="background: #F59E0B;">
            New Tools &amp; Apps
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/SideProject/comments/1r9mmrs/how_do_ai_agent_work/" target="_blank" rel="noopener">How do ai agent work?</a>
    </h3>

    
    <p class="card-summary">Hi everyone, I have been trying to understand how AI coding agents like Cursor or calude work internally, especially from an implementation point of view. I want know about things like: How they index and traverse files inside a project? How they detect relationships across multiple files? How they maintain an understanding of overall repo context ? How they generate code insights or suggested...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">r/LocalLLaMA</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/LocalLLaMA/comments/1r9mkgj/paddleocrvl_now_in_llamacpp/" target="_blank" rel="noopener">PaddleOCR-VL now in llama.cpp</a>
    </h3>

    
    <p class="card-summary">https://github.com/ggml-org/llama.cpp/releases/tag/b8110 So far this is the best performing open-source multilingual OCR model I&#39;ve seen, would appreciate if other people can share their findings. It&#39;s 0.9b so it shouldn&#39;t brick our machines. Some GGUFs &amp;#32; submitted by &amp;#32; /u/PerfectLaw5776 [link] &amp;#32; [comments]</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">r/MachineLearning</span>
        <span class="card-category" style="background: #06B6D4;">
            Social Buzz
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://www.reddit.com/r/MachineLearning/comments/1r9mbtc/p_open_source_llm_gateway_in_rust_looking_for/" target="_blank" rel="noopener">[P] Open source LLM gateway in Rust looking for feedback and contributors</a>
    </h3>

    
    <p class="card-summary">Hey everyone, We have been working on a project called Sentinel. It is a fast LLM gateway written in Rust that gives you a single OpenAI compatible endpoint while routing to multiple providers under the hood. The idea came from dealing with multiple LLM APIs in production and getting tired of managing retries, failover logic, cost tracking, caching, and privacy concerns in every app. We wanted...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16802" target="_blank" rel="noopener">References Improve LLM Alignment in Non-Verifiable Domains</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16802v1 Announce Type: new Abstract: While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16811" target="_blank" rel="noopener">Evaluating Monolingual and Multilingual Large Language Models for Greek Question Answering: The DemosQA Benchmark</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16811v1 Announce Type: new Abstract: Recent advancements in Natural Language Processing and Deep Learning have enabled the development of Large Language Models (LLMs), which have significantly advanced the state-of-the-art across a wide range of tasks, including Question Answering (QA)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16813" target="_blank" rel="noopener">One-step Language Modeling via Continuous Denoising</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16813v1 Announce Type: new Abstract: Language models based on discrete diffusion have attracted widespread interest for their potential to provide faster generation than autoregressive models. In practice, however, they exhibit a sharp degradation of sample quality in the few-step...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16836" target="_blank" rel="noopener">Claim Automation using Large Language Model</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16836v1 Announce Type: new Abstract: While Large Language Models (LLMs) have achieved strong performance on general-purpose language tasks, their deployment in regulated and data-sensitive domains, including insurance, remains limited. Leveraging millions of historical warranty claims...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16843" target="_blank" rel="noopener">BanglaSummEval: Reference-Free Factual Consistency Evaluation for Bangla Summarization</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16843v1 Announce Type: new Abstract: Evaluating factual consistency is essential for reliable text summarization, particularly in high-stakes domains such as healthcare and news. However, most existing evaluation metrics overlook Bangla, a widely spoken yet under-resourced language, and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16852" target="_blank" rel="noopener">Meenz bleibt Meenz, but Large Language Models Do Not Speak Its Dialect</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16852v1 Announce Type: new Abstract: Meenzerisch, the dialect spoken in the German city of Mainz, is also the traditional language of the Mainz carnival, a yearly celebration well known throughout Germany. However, Meenzerisch is on the verge of dying out-a fate it shares with many other...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16938" target="_blank" rel="noopener">ConvApparel: A Benchmark Dataset and Validation Framework for User Simulators in Conversational Recommenders</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16938v1 Announce Type: new Abstract: The promise of LLM-based user simulators to improve conversational AI is hindered by a critical &#34;realism gap,&#34; leading to systems that are optimized for simulated interactions, but may fail to perform well in the real world. We introduce ConvApparel...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16957" target="_blank" rel="noopener">When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism Transfer Between Turkish and English</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16957v1 Announce Type: new Abstract: Euphemisms substitute socially sensitive expressions, often softening or reframing meaning, and their reliance on cultural and pragmatic context complicates modeling across languages. In this study, we investigate how cross-lingual equivalence...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16959" target="_blank" rel="noopener">Eigenmood Space: Uncertainty-Aware Spectral Graph Analysis of Psychological Patterns in Classical Persian Poetry</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16959v1 Announce Type: new Abstract: Classical Persian poetry is a historically sustained archive in which affective life is expressed through metaphor, intertextual convention, and rhetorical indirection. These properties make close reading indispensable while limiting reproducible...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17003" target="_blank" rel="noopener">Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17003v1 Announce Type: new Abstract: Large language models have advanced web agents, yet current agents lack personalization capabilities. Since users rarely specify every detail of their intent, practical web agents must be able to interpret ambiguous queries by inferring user...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17022" target="_blank" rel="noopener">ReIn: Conversational Error Recovery with Reasoning Inception</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17022v1 Announce Type: new Abstract: Conversational agents powered by large language models (LLMs) with tool integration achieve strong performance on fixed task-oriented dialogue datasets but remain vulnerable to unanticipated, user-induced errors. Rather than focusing on error...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17045" target="_blank" rel="noopener">Large Language Models Persuade Without Planning Theory of Mind</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17045v1 Announce Type: new Abstract: A growing body of work attempts to evaluate the theory of mind (ToM) abilities of humans and large language models (LLMs) using static, non-interactive question-and-answer benchmarks. However, theoretical work in the field suggests that first-personal...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17051" target="_blank" rel="noopener">Evaluating Cross-Lingual Classification Approaches Enabling Topic Discovery for Multilingual Social Media Data</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17051v1 Announce Type: new Abstract: Analysing multilingual social media discourse remains a major challenge in natural language processing, particularly when large-scale public debates span across diverse languages. This study investigates how different approaches for cross-lingual text...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17054" target="_blank" rel="noopener">ALPS: A Diagnostic Challenge Set for Arabic Linguistic &amp;amp; Pragmatic Reasoning</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17054v1 Announce Type: new Abstract: While recent Arabic NLP benchmarks focus on scale, they often rely on synthetic or translated data which may benefit from deeper linguistic verification. We introduce ALPS (Arabic Linguistic &amp;amp; Pragmatic Suite), a native, expert-curated diagnostic...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17072" target="_blank" rel="noopener">BankMathBench: A Benchmark for Numerical Reasoning in Banking Scenarios</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17072v1 Announce Type: new Abstract: Large language models (LLMs)-based chatbots are increasingly being adopted in the financial domain, particularly in digital banking, to handle customer inquiries about products such as deposits, savings, and loans. However, these models still exhibit...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17108" target="_blank" rel="noopener">Projective Psychological Assessment of Large Multimodal Models Using Thematic Apperception Tests</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17108v1 Announce Type: new Abstract: Thematic Apperception Test (TAT) is a psychometrically grounded, multidimensional assessment framework that systematically differentiates between cognitive-representational and affective-relational components of personality-like functioning. This test...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17127" target="_blank" rel="noopener">The Emergence of Lab-Driven Alignment Signatures: A Psychometric Framework for Auditing Latent Bias and Compounding Risk in Generative AI</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17127v1 Announce Type: new Abstract: As Large Language Models (LLMs) transition from standalone chat interfaces to foundational reasoning layers in multi-agent systems and recursive evaluation loops (LLM-as-a-judge), the detection of durable, provider-level behavioral signatures becomes...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17194" target="_blank" rel="noopener">What Makes a Good Doctor Response? An Analysis on a Romanian Telemedicine Platform</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17194v1 Announce Type: new Abstract: Text-based telemedicine has become a common mode of care, requiring clinicians to deliver medical advice clearly and effectively in writing. As platforms increasingly rely on patient ratings and feedback, clinicians face growing pressure to maintain...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17262" target="_blank" rel="noopener">Quantifying and Mitigating Socially Desirable Responding in LLMs: A Desirability-Matched Graded Forced-Choice Psychometric Study</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17262v1 Announce Type: new Abstract: Human self-report questionnaires are increasingly used in NLP to benchmark and audit large language models (LLMs), from persona consistency to safety and bias assessments. Yet these instruments presume honest responding; in evaluative contexts, LLMs...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17283" target="_blank" rel="noopener">Towards Cross-lingual Values Assessment: A Consensus-Pluralism Perspective</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17283v1 Announce Type: new Abstract: While large language models (LLMs) have become pivotal to content safety, current evaluation paradigms primarily focus on detecting explicit harms (e.g., violence or hate speech), neglecting the subtler value dimensions conveyed in digital content. To...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17287" target="_blank" rel="noopener">Representation Collapse in Machine Translation Through the Lens of Angular Dispersion</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17287v1 Announce Type: new Abstract: Modern neural translation models based on the Transformer architecture are known for their high performance, particularly when trained on high-resource datasets. A standard next-token prediction training strategy, while widely adopted in practice, may...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17316" target="_blank" rel="noopener">Same Meaning, Different Scores: Lexical and Syntactic Sensitivity in LLM Evaluation</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17316v1 Announce Type: new Abstract: The rapid advancement of Large Language Models (LLMs) has established standardized evaluation benchmarks as the primary instrument for model comparison. Yet, their reliability is increasingly questioned due to sensitivity to shallow variations in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17366" target="_blank" rel="noopener">RPDR: A Round-trip Prediction-Based Data Augmentation Framework for Long-Tail Question Answering</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17366v1 Announce Type: new Abstract: Long-tail question answering presents significant challenges for large language models (LLMs) due to their limited ability to acquire and accurately recall less common knowledge. Retrieval-augmented generation (RAG) systems have shown great promise in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17377" target="_blank" rel="noopener">The Role of the Availability Heuristic in Multiple-Choice Answering Behaviour</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17377v1 Announce Type: new Abstract: When students are unsure of the correct answer to a multiple-choice question (MCQ), guessing is common practice. The availability heuristic, proposed by A. Tversky and D. Kahneman in 1973, suggests that the ease with which relevant instances come to...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17424" target="_blank" rel="noopener">Diverse Word Choices, Same Reference: Annotating Lexically-Rich Cross-Document Coreference</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17424v1 Announce Type: new Abstract: Cross-document coreference resolution (CDCR) identifies and links mentions of the same entities and events across related documents, enabling content analysis that aggregates information at the level of discourse participants. However, existing...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17425" target="_blank" rel="noopener">Evaluating Extremely Low-Resource Machine Translation: A Comparative Study of ChrF++ and BLEU Metrics</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17425v1 Announce Type: new Abstract: Evaluating machine translation (MT) quality in extremely low-resource language (ELRL) scenarios poses unique challenges, as widely used metrics such as BLEU, effective in high-resource settings, often misrepresent quality in data-scarce contexts. This...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17431" target="_blank" rel="noopener">Fine-Grained Uncertainty Quantification for Long-Form Language Model Outputs: A Comparative Study</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17431v1 Announce Type: new Abstract: Uncertainty quantification has emerged as an effective approach to closed-book hallucination detection for LLMs, but existing methods are largely designed for short-form outputs and do not generalize well to long-form generation. We introduce a...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17443" target="_blank" rel="noopener">AIDG: Evaluating Asymmetry Between Information Extraction and Containment in Multi-Turn Dialogue</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17443v1 Announce Type: new Abstract: Evaluating the strategic reasoning capabilities of Large Language Models (LLMs) requires moving beyond static benchmarks to dynamic, multi-turn interactions. We introduce AIDG (Adversarial Information Deduction Game), a game-theoretic framework that...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17445" target="_blank" rel="noopener">ABCD: All Biases Come Disguised</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17445v1 Announce Type: new Abstract: Multiple-choice question (MCQ) benchmarks have been a standard evaluation practice for measuring LLMs&#39; ability to reason and answer knowledge-based questions. Through a synthetic NonsenseQA benchmark, we observe that different LLMs exhibit varying...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17465" target="_blank" rel="noopener">Entropy-Based Data Selection for Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17465v1 Announce Type: new Abstract: Modern language models (LMs) increasingly require two critical resources: computational resources and data resources. Data selection techniques can effectively reduce the amount of training data required for fine-tuning LMs. However, their...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17467" target="_blank" rel="noopener">PEACE 2.0: Grounded Explanations and Counter-Speech for Combating Hate Expressions</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17467v1 Announce Type: new Abstract: The increasing volume of hate speech on online platforms poses significant societal challenges. While the Natural Language Processing community has developed effective methods to automatically detect the presence of hate speech, responses to it...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17469" target="_blank" rel="noopener">Auditing Reciprocal Sentiment Alignment: Inversion Risk, Dialect Representation and Intent Misalignment in Transformers</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17469v1 Announce Type: new Abstract: The core theme of bidirectional alignment is ensuring that AI systems accurately understand human intent and that humans can trust AI behavior. However, this loop fractures significantly across language barriers. Our research addresses Cross-Lingual...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17475" target="_blank" rel="noopener">Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17475v1 Announce Type: new Abstract: Large Language Models (LLMs) consistently excel in diverse medical Natural Language Processing (NLP) tasks, yet their substantial computational requirements often limit deployment in real-world healthcare settings. In this work, we investigate whether...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17513" target="_blank" rel="noopener">Bridging the Domain Divide: Supervised vs. Zero-Shot Clinical Section Segmentation from MIMIC-III to Obstetrics</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17513v1 Announce Type: new Abstract: Clinical free-text notes contain vital patient information. They are structured into labelled sections; recognizing these sections has been shown to support clinical decision-making and downstream NLP tasks. In this paper, we advance clinical section...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17542" target="_blank" rel="noopener">Using LLMs for Knowledge Component-level Correctness Labeling in Open-ended Coding Problems</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17542v1 Announce Type: new Abstract: Fine-grained skill representations, commonly referred to as knowledge components (KCs), are fundamental to many approaches in student modeling and learning analytics. However, KC-level correctness labels are rarely available in real-world datasets...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17546" target="_blank" rel="noopener">Learning to Stay Safe: Adaptive Regularization Against Safety Degradation during Fine-Tuning</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17546v1 Announce Type: new Abstract: Instruction-following language models are trained to be helpful and safe, yet their safety behavior can deteriorate under benign fine-tuning and worsen under adversarial updates. Existing defenses often offer limited protection or force a trade-off...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17588" target="_blank" rel="noopener">Modeling Distinct Human Interaction in Web Agents</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17588v1 Announce Type: new Abstract: Despite rapid progress in autonomous web agents, human involvement remains essential for shaping preferences and correcting agent behavior as tasks unfold. However, current agentic systems lack a principled understanding of when and why humans...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17598" target="_blank" rel="noopener">The Cascade Equivalence Hypothesis: When Do Speech LLMs Behave Like ASR$\rightarrow$LLM Pipelines?</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17598v1 Announce Type: new Abstract: Current speech LLMs largely perform implicit ASR: on tasks solvable from a transcript, they are behaviorally and mechanistically equivalent to simple Whisper$\to$LLM cascades. We show this through matched-backbone testing across four speech LLMs and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17623" target="_blank" rel="noopener">Unmasking the Factual-Conceptual Gap in Persian Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17623v1 Announce Type: new Abstract: While emerging Persian NLP benchmarks have expanded into pragmatics and politeness, they rarely distinguish between memorized cultural facts and the ability to reason about implicit social norms. We introduce DivanBench, a diagnostic benchmark focused...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17653" target="_blank" rel="noopener">Differences in Typological Alignment in Language Models&#39; Treatment of Differential Argument Marking</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17653v1 Announce Type: new Abstract: Recent work has shown that language models (LMs) trained on synthetic corpora can exhibit typological preferences that resemble cross-linguistic regularities in human languages, particularly for syntactic phenomena such as word order. In this paper...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17655" target="_blank" rel="noopener">What Language is This? Ask Your Tokenizer</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17655v1 Announce Type: new Abstract: Language Identification (LID) is an important component of many multilingual natural language processing pipelines, where it facilitates corpus curation, training data analysis, and cross-lingual evaluation of large language models. Despite...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17664" target="_blank" rel="noopener">Sink-Aware Pruning for Diffusion Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17664v1 Announce Type: new Abstract: Diffusion Language Models (DLMs) incur high inference cost due to iterative denoising, motivating efficient pruning. Existing pruning heuristics largely inherited from autoregressive (AR) LLMs, typically preserve attention sink tokens because AR sinks...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16715" target="_blank" rel="noopener">Retrieval Augmented (Knowledge Graph), and Large Language Model-Driven Design Structure Matrix (DSM) Generation of Cyber-Physical Systems</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16715v1 Announce Type: cross Abstract: We explore the potential of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG), and Graph-based RAG (GraphRAG) for generating Design Structure Matrices (DSMs). We test these methods on two distinct use cases -- a power screwdriver...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16729" target="_blank" rel="noopener">Intent Laundering: AI Safety Datasets Are Not What They Seem</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16729v1 Announce Type: cross Abstract: We systematically evaluate the quality of widely used AI safety datasets from two perspectives: in isolation and in practice. In isolation, we examine how well these datasets reflect real-world attacks based on three key properties: driven by...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16755" target="_blank" rel="noopener">PREFER: An Ontology for the PREcision FERmentation Community</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16755v1 Announce Type: cross Abstract: Precision fermentation relies on microbial cell factories to produce sustainable food, pharmaceuticals, chemicals, and biofuels. Specialized laboratories such as biofoundries are advancing these processes using high-throughput bioreactor platforms...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16784" target="_blank" rel="noopener">Omitted Variable Bias in Language Models Under Distribution Shift</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16784v1 Announce Type: cross Abstract: Despite their impressive performance on a wide variety of tasks, modern language models remain susceptible to distribution shifts, exhibiting brittle behavior when evaluated on data that differs in distribution from their training data. In this...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16787" target="_blank" rel="noopener">Better Think Thrice: Learning to Reason Causally with Double Counterfactual Consistency</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16787v1 Announce Type: cross Abstract: Despite their strong performance on reasoning benchmarks, large language models (LLMs) have proven brittle when presented with counterfactual questions, suggesting weaknesses in their causal reasoning ability. While recent work has demonstrated that...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16819" target="_blank" rel="noopener">Hybrid-Gym: Training Coding Agents to Generalize Across Tasks</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16819v1 Announce Type: cross Abstract: When assessing the quality of coding agents, predominant benchmarks focus on solving single issues on GitHub, such as SWE-Bench. In contrast, in real use, these agents solve more various and complex tasks that involve other skills such as exploring...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16832" target="_blank" rel="noopener">IndicJR: A Judge-Free Benchmark of Jailbreak Robustness in South Asian Languages</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16832v1 Announce Type: cross Abstract: Safety alignment of large language models (LLMs) is mostly evaluated in English and contract-bound, leaving multilingual vulnerabilities understudied. We introduce \textbf{Indic Jailbreak Robustness (IJR)}, a judge-free benchmark for adversarial...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16839" target="_blank" rel="noopener">Training Large Reasoning Models Efficiently via Progressive Thought Encoding</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16839v1 Announce Type: cross Abstract: Large reasoning models (LRMs) excel on complex problems but face a critical barrier to efficiency: reinforcement learning (RL) training requires long rollouts for outcome-based rewards, where autoregressive decoding dominates time and memory usage...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16855" target="_blank" rel="noopener">Mobile-Agent-v3.5: Multi-platform Fundamental GUI Agents</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16855v1 Announce Type: cross Abstract: The paper introduces GUI-Owl-1.5, the latest native GUI agent model that features instruct/thinking variants in multiple sizes (2B/4B/8B/32B/235B) and supports a range of platforms (desktop, mobile, browser, and more) to enable cloud-edge...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16976" target="_blank" rel="noopener">HQFS: Hybrid Quantum Classical Financial Security with VQC Forecasting, QUBO Annealing, and Audit-Ready Post-Quantum Signing</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16976v1 Announce Type: cross Abstract: Here&#39;s the corrected paragraph with all punctuation and formatting issues fixed: Financial risk systems usually follow a two-step routine: a model predicts return or risk, and then an optimizer makes a decision such as a portfolio rebalance. In...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16979" target="_blank" rel="noopener">Characterizing the Predictive Impact of Modalities with Supervised Latent-Variable Modeling</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16979v1 Announce Type: cross Abstract: Despite the recent success of Multimodal Large Language Models (MLLMs), existing approaches predominantly assume the availability of multiple modalities during training and inference. In practice, multimodal data is often incomplete because...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.16997" target="_blank" rel="noopener">Exploring LLMs for User Story Extraction from Mockups</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.16997v1 Announce Type: cross Abstract: User stories are one of the most widely used artifacts in the software industry to define functional requirements. In parallel, the use of high-fidelity mockups facilitates end-user participation in defining their needs. In this work, we explore how...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17001" target="_blank" rel="noopener">Sonar-TS: Search-Then-Verify Natural Language Querying for Time Series Databases</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17001v1 Announce Type: cross Abstract: Natural Language Querying for Time Series Databases (NLQ4TSDB) aims to assist non-expert users retrieve meaningful events, intervals, and summaries from massive temporal records. However, existing Text-to-SQL methods are not designed for continuous...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17004" target="_blank" rel="noopener">Arcee Trinity Large Technical Report</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17004v1 Announce Type: cross Abstract: We present the technical report for Arcee Trinity Large, a sparse Mixture-of-Experts model with 400B total parameters and 13B activated per token. Additionally, we report on Trinity Nano and Trinity Mini, with Trinity Nano having 6B total parameters...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17053" target="_blank" rel="noopener">RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17053v1 Announce Type: cross Abstract: Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17063" target="_blank" rel="noopener">Sign Lock-In: Randomly Initialized Weight Signs Persist and Bottleneck Sub-Bit Model Compression</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17063v1 Announce Type: cross Abstract: Sub-bit model compression seeks storage below one bit per weight; as magnitudes are aggressively compressed, the sign bit becomes a fixed-cost bottleneck. Across Transformers, CNNs, and MLPs, learned sign matrices resist low-rank approximation and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17221" target="_blank" rel="noopener">From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan&#39;s Humanities and Social Sciences</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17221v1 Announce Type: cross Abstract: Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a &#34;methodological...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17229" target="_blank" rel="noopener">Mechanistic Interpretability of Cognitive Complexity in LLMs via Linear Probing using Bloom&#39;s Taxonomy</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17229v1 Announce Type: cross Abstract: The black-box nature of Large Language Models necessitates novel evaluation frameworks that transcend surface-level performance metrics. This study investigates the internal neural representations of cognitive complexity using Bloom&#39;s Taxonomy as a...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17288" target="_blank" rel="noopener">ArXiv-to-Model: A Practical Study of Scientific LM Training</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17288v1 Announce Type: cross Abstract: While frontier large language models demonstrate strong reasoning and mathematical capabilities, the practical process of training domain-specialized scientific language models from raw sources remains under-documented. In this work, we present a...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17327" target="_blank" rel="noopener">WebFAQ 2.0: A Multilingual QA Dataset with Mined Hard Negatives for Dense Retrieval</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17327v1 Announce Type: cross Abstract: We introduce WebFAQ 2.0, a new version of the WebFAQ dataset, containing 198 million FAQ-based natural question-answer pairs across 108 languages. Compared to the previous version, it significantly expands multilingual coverage and the number of...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17413" target="_blank" rel="noopener">DAVE: A Policy-Enforcing LLM Spokesperson for Secure Multi-Document Data Sharing</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17413v1 Announce Type: cross Abstract: In current inter-organizational data spaces, usage policies are enforced mainly at the asset level: a whole document or dataset is either shared or withheld. When only parts of a document are sensitive, providers who want to avoid leaking protected...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17483" target="_blank" rel="noopener">What Do LLMs Associate with Your Name? A Human-Centered Black-Box Audit of Personal Data</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17483v1 Announce Type: cross Abstract: Large language models (LLMs), and conversational agents based on them, are exposed to personal data (PD) during pre-training and during user interactions. Prior work shows that PD can resurface, yet users lack insight into how strongly models...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17526" target="_blank" rel="noopener">The Anxiety of Influence: Bloom Filters in Transformer Attention Heads</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17526v1 Announce Type: cross Abstract: Some transformer attention heads appear to function as membership testers, dedicating themselves to answering the question &#34;has this token appeared before in the context?&#34; We identify these heads across four language models (GPT-2 small, medium, and...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17544" target="_blank" rel="noopener">Evaluating Chain-of-Thought Reasoning through Reusability and Verifiability</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17544v1 Announce Type: cross Abstract: In multi-agent IR pipelines for tasks such as search and ranking, LLM-based agents exchange intermediate reasoning in terms of Chain-of-Thought (CoT) with each other. Current CoT evaluation narrowly focuses on target task accuracy. However, this...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17547" target="_blank" rel="noopener">KLong: Training LLM Agent for Extremely Long-horizon Tasks</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17547v1 Announce Type: cross Abstract: This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17645" target="_blank" rel="noopener">Pushing the Frontier of Black-Box LVLM Attacks via Fine-Grained Detail Targeting</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17645v1 Announce Type: cross Abstract: Black-box adversarial attacks on Large Vision-Language Models (LVLMs) are challenging due to missing gradients and complex multimodal boundaries. While prior state-of-the-art transfer-based approaches like M-Attack perform well using local...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.17663" target="_blank" rel="noopener">CLEF HIPE-2026: Evaluating Accurate and Efficient Person-Place Relation Extraction from Multilingual Historical Texts</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.17663v1 Announce Type: cross Abstract: HIPE-2026 is a CLEF evaluation lab dedicated to person-place relation extraction from noisy, multilingual historical texts. Building on the HIPE-2020 and HIPE-2022 campaigns, it extends the series toward semantic relation extraction by targeting the...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2212.06543" target="_blank" rel="noopener">Improving Stance Detection by Leveraging Measurement Knowledge from Social Sciences: A Case Study of Dutch Political Tweets and Traditional Gender Role Division</a>
    </h3>

    
    <p class="card-summary">arXiv:2212.06543v3 Announce Type: replace Abstract: Stance detection concerns automatically determining the viewpoint (i.e., in favour of, against, or neutral) of a text&#39;s author towards a target. Stance detection has been applied to many research topics, among which the detection of stances behind...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2412.06106" target="_blank" rel="noopener">Efficient Context Propagating Perceiver Architectures for Auto-Regressive Language Modeling</a>
    </h3>

    
    <p class="card-summary">arXiv:2412.06106v2 Announce Type: replace Abstract: One of the key challenges in Transformer architectures is the quadratic complexity of the attention mechanism, which limits the efficient processing of long sequences. Many recent research works have attempted to provide a reduction from the...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2502.10361" target="_blank" rel="noopener">Enhancing Multilingual LLM Pretraining with Model-Based Data Selection</a>
    </h3>

    
    <p class="card-summary">arXiv:2502.10361v2 Announce Type: replace Abstract: Dataset curation has become a basis for strong large language model (LLM) performance. While various rule-based filtering heuristics exist for English and multilingual datasets, model-based filtering techniques have primarily focused on English...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2505.02819" target="_blank" rel="noopener">ReplaceMe: Network Simplification via Depth Pruning and Transformer Block Linearization</a>
    </h3>

    
    <p class="card-summary">arXiv:2505.02819v4 Announce Type: replace Abstract: We introduce ReplaceMe, a generalized training-free depth pruning method that effectively replaces transformer blocks with a linear operation, while maintaining high performance for low compression ratios. In contrast to conventional pruning...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2505.20650" target="_blank" rel="noopener">FinTagging: Benchmarking LLMs for Extracting and Structuring Financial Information</a>
    </h3>

    
    <p class="card-summary">arXiv:2505.20650v4 Announce Type: replace Abstract: Accurate interpretation of numerical data in financial reports is critical for markets and regulators. Although XBRL (eXtensible Business Reporting Language) provides a standard for tagging financial figures, mapping thousands of facts to over 10k...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.06968" target="_blank" rel="noopener">A dependently-typed calculus of event telicity and culminativity</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.06968v2 Announce Type: replace Abstract: We present a dependently-typed cross-linguistic framework for analyzing the telicity and culminativity of events, accompanied by examples of using our framework to model English sentences. Our framework consists of two parts. In the nominal...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.11798" target="_blank" rel="noopener">Persona-driven Simulation of Voting Behavior in the European Parliament with Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.11798v3 Announce Type: replace Abstract: Large Language Models (LLMs) display remarkable capabilities to understand or even produce political discourse but have been found to consistently exhibit a progressive left-leaning bias. At the same time, so-called persona or identity prompts...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.16777" target="_blank" rel="noopener">DistillNote: Toward a Functional Evaluation Framework of LLM-Generated Clinical Note Summaries</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.16777v2 Announce Type: replace Abstract: Large language models (LLMs) are increasingly used to generate summaries from clinical notes. However, their ability to preserve essential diagnostic information remains underexplored, which could lead to serious risks for patient care. This study...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.20642" target="_blank" rel="noopener">$\pi$-CoT: Prolog-Initialized Chain-of-Thought Prompting for Multi-Hop Question-Answering</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.20642v2 Announce Type: replace Abstract: Chain-of-Thought (CoT) prompting significantly enhances large language models&#39; (LLMs) problem-solving capabilities, but still struggles with complex multi-hop questions, often falling into circular reasoning patterns or deviating from the logical...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2507.19634" target="_blank" rel="noopener">MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks</a>
    </h3>

    
    <p class="card-summary">arXiv:2507.19634v3 Announce Type: replace Abstract: Recent advances in large language models have laid the foundation for multimodal LLMs (MLLMs), which unify text, speech, and vision within a single framework. As these models are rapidly evolving toward general-purpose instruction following across...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2508.14292" target="_blank" rel="noopener">Tokens with Meaning: A Hybrid Tokenization Approach for Turkish</a>
    </h3>

    
    <p class="card-summary">arXiv:2508.14292v2 Announce Type: replace Abstract: Tokenization shapes how language models perceive morphology and meaning in NLP, yet widely used frequency-driven subword tokenizers (e.g., Byte Pair Encoding and WordPiece) can fragment morphologically rich and agglutinative languages in ways that...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.04080" target="_blank" rel="noopener">PoLi-RL: A Point-to-List Reinforcement Learning Framework for Conditional Semantic Textual Similarity</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.04080v2 Announce Type: replace Abstract: Conditional Semantic Textual Similarity (C-STS) measures the semantic proximity between text segments under a specific condition, thereby overcoming the ambiguity inherent in traditional STS. However, existing methods are largely confined to...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.08886" target="_blank" rel="noopener">FinAuditing: A Financial Taxonomy-Structured Multi-Document Benchmark for Evaluating LLMs</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.08886v2 Announce Type: replace Abstract: Going beyond simple text processing, financial auditing requires detecting semantic, structural, and numerical inconsistencies across large-scale disclosures. As financial reports are filed in XBRL, a structured XML format governed by accounting...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.13749" target="_blank" rel="noopener">Assessing Web Search Credibility and Response Groundedness in Chat Assistants</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.13749v2 Announce Type: replace Abstract: Chat assistants increasingly integrate web search functionality, enabling them to retrieve and cite external sources. While this promises more reliable answers, it also raises the risk of amplifying misinformation from low-credibility sources. In...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.21193" target="_blank" rel="noopener">Estonian Native Large Language Model Benchmark</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.21193v2 Announce Type: replace Abstract: The availability of LLM benchmarks for the Estonian language is limited, and a comprehensive evaluation comparing the performance of different LLMs on Estonian tasks has yet to be conducted. We introduce a new benchmark for evaluating LLMs in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.27118" target="_blank" rel="noopener">Probability Distributions Computed by Hard-Attention Transformers</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.27118v2 Announce Type: replace Abstract: Most expressivity results for transformers treat them as language recognizers (which accept or reject strings), and not as they are used in practice, as language models (which generate strings autoregressively and probabilistically). We...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.07989" target="_blank" rel="noopener">State of the Art in Text Classification for South Slavic Languages: Fine-Tuning or Prompting?</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.07989v2 Announce Type: replace Abstract: Until recently, fine-tuned BERT-like models provided state-of-the-art performance on text classification tasks. With the rise of instruction-tuned decoder-only models, commonly known as large language models (LLMs), the field has increasingly...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2511.18696" target="_blank" rel="noopener">Empathetic Cascading Networks: A Multi-Stage Prompting Technique for Reducing Social Biases in Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2511.18696v2 Announce Type: replace Abstract: This report presents the Empathetic Cascading Networks (ECN) framework, a multi-stage prompting method designed to enhance the empathetic and inclusive capabilities of large language models. ECN employs four stages: Perspective Adoption, Emotional...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2512.03870" target="_blank" rel="noopener">Reconstructing KV Caches with Cross-layer Fusion For Enhanced Transformers</a>
    </h3>

    
    <p class="card-summary">arXiv:2512.03870v3 Announce Type: replace Abstract: Transformer decoders have achieved strong results across tasks, but the memory required for the KV cache becomes prohibitive at long sequence lengths. Although Cross-layer KV Cache sharing (e.g., YOCO, CLA) offers a path to mitigate KV Cache...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2512.08646" target="_blank" rel="noopener">QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2512.08646v2 Announce Type: replace Abstract: We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2512.11108" target="_blank" rel="noopener">Explanation Bias is a Product: Revealing the Hidden Lexical and Position Preferences in Post-Hoc Feature Attribution</a>
    </h3>

    
    <p class="card-summary">arXiv:2512.11108v2 Announce Type: replace Abstract: Good quality explanations strengthen the understanding of language models and data. Feature attribution methods, such as Integrated Gradient, are a type of post-hoc explainer that can provide token-level insights. However, explanations on the same...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.06932" target="_blank" rel="noopener">Symphonym: Universal Phonetic Embeddings for Cross-Script Name Matching</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.06932v2 Announce Type: replace Abstract: Linking names across historical sources, languages, and writing systems remains a fundamental challenge in digital humanities and geographic information retrieval. Existing approaches require language-specific phonetic algorithms or fail to...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2601.12815" target="_blank" rel="noopener">Multimodal Multi-Agent Empowered Legal Judgment Prediction</a>
    </h3>

    
    <p class="card-summary">arXiv:2601.12815v5 Announce Type: replace Abstract: Legal Judgment Prediction (LJP) aims to predict the outcomes of legal cases based on factual descriptions, serving as a fundamental task to advance the development of legal systems. Traditional methods often rely on statistical analyses or...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.02377" target="_blank" rel="noopener">Proof-RM: A Scalable and Generalizable Reward Model for Math Proof</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.02377v2 Announce Type: replace Abstract: While Large Language Models (LLMs) have demonstrated strong math reasoning abilities through Reinforcement Learning with *Verifiable Rewards* (RLVR), many advanced mathematical problems are proof-based, with no guaranteed way to determine the...</p>
    

    
</article>
    
        <article class="article-card trending">
    
    <span class="trending-badge">TRENDING</span>
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2602.06275" target="_blank" rel="noopener">RoPE-LIME: RoPE-Space Locality + Sparse-K Sampling for Efficient LLM Attribution</a>
    </h3>

    
    <p class="card-summary">arXiv:2602.06275v2 Announce Type: replace Abstract: Explaining closed-source Large Language Model (LLM) outputs is challenging because API access prevents gradient-based attribution, while perturbation methods are costly and noisy when they depend on regenerated text. We introduce \textbf{Rotary...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2503.23339" target="_blank" rel="noopener">A Scalable Framework for Evaluating Health Language Models</a>
    </h3>

    
    <p class="card-summary">arXiv:2503.23339v3 Announce Type: replace-cross Abstract: Large language models (LLMs) have emerged as powerful tools for analyzing complex datasets. Recent studies demonstrate their potential to generate useful, personalized responses when provided with patient-specific health information that...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2505.17508" target="_blank" rel="noopener">On the Design of KL-Regularized Policy Gradient Algorithms for LLM Reasoning</a>
    </h3>

    
    <p class="card-summary">arXiv:2505.17508v4 Announce Type: replace-cross Abstract: Policy gradient algorithms have been successfully applied to enhance the reasoning capabilities of large language models (LLMs). KL regularization is ubiquitous, yet the design surface, choice of KL direction (forward vs. reverse)...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.02529" target="_blank" rel="noopener">Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.02529v2 Announce Type: replace-cross Abstract: Web applications are critical to modern software ecosystems, yet ensuring their reliability remains challenging due to the complexity and dynamic nature of web interfaces. Recent advances in large language models (LLMs) have shown promise in...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2506.15733" target="_blank" rel="noopener">$\texttt{SPECS}$: Faster Test-Time Scaling through Speculative Drafts</a>
    </h3>

    
    <p class="card-summary">arXiv:2506.15733v2 Announce Type: replace-cross Abstract: Scaling test-time compute has driven the recent advances in the reasoning capabilities of large language models (LLMs), typically by allocating additional computation for more thorough exploration. However, increased compute often comes at...</p>
    

    
</article>
    
        <article class="article-card">
    

    <div class="card-meta">
        <span class="card-source">ArXiv - Computation &amp; Language</span>
        <span class="card-category" style="background: #4F46E5;">
            AI &amp; LLMs
        </span>
        <span class="card-time">1h ago</span>
    </div>

    <h3 class="card-title">
        <a href="https://arxiv.org/abs/2510.09201" target="_blank" rel="noopener">Multimodal Prompt Optimization: Why Not Leverage Multiple Modalities for MLLMs</a>
    </h3>

    
    <p class="card-summary">arXiv:2510.09201v2 Announce Type: replace-cross Abstract: Large Language Models (LLMs) have shown remarkable success, and their multimodal expansions (MLLMs) further unlock capabilities spanning images, videos, and other modalities beyond text. However, despite this shift, prompt optimization...</p>
    

    
</article>
    
</div>


    </main>

    <footer class="site-footer">
        <div class="container">
            <p>Last updated: February 20, 2026 at 06:38 UTC</p>
            <p>488 articles from 20 sources</p>
            <p>Daily Signal Feed &mdash; AI, Web3 &amp; Emerging Tech Aggregator</p>
        </div>
    </footer>

    <script>
    // Client-side search filter
    document.addEventListener('DOMContentLoaded', function() {
        const searchBar = document.querySelector('.search-bar');
        if (searchBar) {
            searchBar.addEventListener('input', function(e) {
                const query = e.target.value.toLowerCase();
                const cards = document.querySelectorAll('.article-card, .archive-item');
                cards.forEach(function(card) {
                    const text = card.textContent.toLowerCase();
                    card.style.display = text.includes(query) ? '' : 'none';
                });
            });
        }
    });
    </script>
</body>
</html>